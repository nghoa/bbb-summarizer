[
    {
        "Duration": 21,
        "Sent ID": "",
        "Spoken words": "okay high 'm name much show death present work detecting conversations customers virtual agents joint work ibm loving high fi yorktown",
        "Sent i": 0,
        "Sent Text": "test automated conversational agents (chatbots) are becoming widely used for various tasks such as personal assistants or as customer service agents.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 7,
        "Sent ID": "",
        "Spoken words": "okay one second okay sorry okay think",
        "Sent i": 3,
        "Sent Text": "still, chatbots may behave extremely badly, leading to conversations so off-the-mark that only a human agent could step in and salvage them.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 9,
        "Sent ID": "",
        "Spoken words": "stuff phoenician egregious egregious definition outstandingly bad shocking heard",
        "Sent i": 6,
        "Sent Text": "in this paper we study detecting these egregious conversations that can arise in numerous ways.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 8,
        "Sent ID": "",
        "Spoken words": "known interest using virtual agent increasing specifically prediction",
        "Sent i": 0,
        "Sent Text": "test automated conversational agents (chatbots) are becoming widely used for various tasks such as personal assistants or as customer service agents.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 5,
        "Sent ID": "",
        "Spoken words": "twenty twenty eighty percent businesses",
        "Sent i": 1,
        "Sent Text": "recent studies project that 80% of businesses plan to use chatbots by 20201, and that chatbots will power 85% of customer service interactions by the year 20202.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 8,
        "Sent ID": "",
        "Spoken words": "virtual agents even specifically look customer care main",
        "Sent i": 0,
        "Sent Text": "test automated conversational agents (chatbots) are becoming widely used for various tasks such as personal assistants or as customer service agents.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 5,
        "Sent ID": "",
        "Spoken words": "eighty five percent interactions provide",
        "Sent i": 1,
        "Sent Text": "recent studies project that 80% of businesses plan to use chatbots by 20201, and that chatbots will power 85% of customer service interactions by the year 20202.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 2,
        "Sent ID": "",
        "Spoken words": "powered virtual",
        "Sent i": 2,
        "Sent Text": "this increasing usage is mainly due to advances in artificial intelligence and natural language processing (hirschberg and manning, 2015) along with increasingly capable chat development environments, leading to improvements in conversational richness and robustness.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 15,
        "Sent ID": "",
        "Spoken words": "agents course good us however either experience know virtual agents might behave really bad lead",
        "Sent i": 3,
        "Sent Text": "still, chatbots may behave extremely badly, leading to conversations so off-the-mark that only a human agent could step in and salvage them.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 4,
        "Sent ID": "",
        "Spoken words": "loss customer loyalty even",
        "Sent i": 4,
        "Sent Text": "consequences of these failures may include loss of customer goodwill and associated revenue, and even exposure to litigation if the failures can be shown to include fraudulent claims.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 4,
        "Sent ID": "",
        "Spoken words": "ways use okay sir",
        "Sent i": 13,
        "Sent Text": "the resulting customer frustration may not surface in easily detectable ways such as the appearance of all caps, shouting to a speech recognizer, or the use of profanity or extreme punctuation.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 3,
        "Sent ID": "",
        "Spoken words": "real example conversation",
        "Sent i": 15,
        "Sent Text": "consider, for example, the anonymized but representative conversation depicted in figure 1.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 36,
        "Sent ID": "",
        "Spoken words": "n't deal let take okay customer left agents right customer asking quotes travel wants know details agent kind understand telling consider purchased ticket customer interested n't want buy want know details agents actually missing gifts think",
        "Sent i": 16,
        "Sent Text": "here the customer aims to understand the details of a flight ticket.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 13,
        "Sent ID": "",
        "Spoken words": "already wants go next online lyor process rent cop customer asking rule person",
        "Sent i": 17,
        "Sent Text": "in the first two turns, the chatbot misses the customer’s intentions, which leads to the customer asking “are you a real person?”.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 40,
        "Sent ID": "",
        "Spoken words": "response develop since assistant trained answer questions drivers get ask question customer trying start getting little bit annoyed ask specific question got sell agent picking answering 'm trained yet 'm still learning may want forget phase question time customer thing",
        "Sent i": 18,
        "Sent Text": "the customer then tries to explain what went wrong, but the chatbot has insufficient exposure to this sort of utterance to provide anything but the default response (“i’m not trained on that”).",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 16,
        "Sent ID": "",
        "Spoken words": "frustrated anger well pointless talk real life person answer n't currently live agents checked online okay",
        "Sent i": 19,
        "Sent Text": "the response seems to upset the customer and leads to a request for a human agent, which is rejected by the system (“we don’t currently have live agents”).",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 9,
        "Sent ID": "",
        "Spoken words": "define egregious conversations okay course bunch well top elected",
        "Sent i": 32,
        "Sent Text": "we review related work, then we formally define the methodology for detecting egregious conversations.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 9,
        "Sent ID": "",
        "Spoken words": "book festal works todd looking computer complementary problems try",
        "Sent i": 36,
        "Sent Text": "these works studied the complementary problem of detecting and measuring user satisfaction and engagement.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 5,
        "Sent ID": "",
        "Spoken words": "maximize data previous work coming",
        "Sent i": 37,
        "Sent Text": "early work by (walker et al., 1997, 2001) discussed a framework that maximizes the user satisfaction by considering measures such as number of inappropriate utterances, recognition rates, number of times user requests repetitions, number of turns per interaction, etc.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 2,
        "Sent ID": "",
        "Spoken words": "mine systems",
        "Sent i": 39,
        "Sent Text": "other works focus on predicting the user engagement in such systems.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 4,
        "Sent ID": "",
        "Spoken words": "data use dialogue logo",
        "Sent i": 43,
        "Sent Text": "in our work, we likewise use emotion analysis as predictive features for egregious conversation.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 19,
        "Sent ID": "",
        "Spoken words": "specific setting late late stood two thousand seventeen somewhat thought trying study reason customers rephrasing different reasons affect satisfaction",
        "Sent i": 45,
        "Sent Text": "specifically, in (sarikaya, 2017) they reported on how the different reasons affect the users’ satisfaction.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 2,
        "Sent ID": "",
        "Spoken words": "dissatisfaction finally",
        "Sent i": 46,
        "Sent Text": "in (sano et al., 2017) they focused on how to automatically predict the reason for user’s dissatisfaction using different features.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 7,
        "Sent ID": "",
        "Spoken words": "also looking dialog break break downs walker",
        "Sent i": 49,
        "Sent Text": "in (walker et al., 2000; hastie et al., 2002) the authors also looked for problems in a specific setting of spoken conversations.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 3,
        "Sent ID": "",
        "Spoken words": "trying torrents level",
        "Sent i": 53,
        "Sent Text": "in (steidl et al., 2004) they measured dialogue success at the turn level as a way of predicting the success of a conversation as a whole.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 11,
        "Sent ID": "",
        "Spoken words": "try understand utterance break data japanese chat okay dealing would like",
        "Sent i": 57,
        "Sent Text": "all these measures may serve as reasons for a conversation turning egregious, but none try to capture or predict it directly.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 26,
        "Sent ID": "",
        "Spoken words": "sit extracted lead companies provide customer support using virtual agents company using similar line totally different domains one company business logic course arm system extract thousand",
        "Sent i": 60,
        "Sent Text": "they found that a combination of exaggerated customer expectations along with a reduction in agent performance (e.g., failure to listen to the consumer, being too intrusive) caused customers to stop using such systems.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 21,
        "Sent ID": "",
        "Spoken words": "conversations randomly see local distribution conversation never see conversation company much twice longer company okay recall thought try detect group conversation",
        "Sent i": 64,
        "Sent Text": "the objective of this work is to reliably detect egregious conversations between a human and a virtual agent.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 12,
        "Sent ID": "",
        "Spoken words": "treat problem binary classification problem target classes egregious awning gregis input classifieds",
        "Sent i": 65,
        "Sent Text": "we treat this as a binary classification task, where the target classes are “egregious” and “non-egregious”.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 6,
        "Sent ID": "",
        "Spoken words": "basically complete conversation classification done end",
        "Sent i": 66,
        "Sent Text": "while we are currently applying this to complete conversations (i.e., the classification is done on the whole conversation), some of the features examined here could likely be used to detect egregious conversations as they were unfolding in real time.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 22,
        "Sent ID": "",
        "Spoken words": "conversation struck dot three different feature sets conversation feature coming agent response customer input interaction feature customer agents also low feature context",
        "Sent i": 67,
        "Sent Text": "to perform egregious conversation detection, features from both customer inputs and agent responses are extracted, together with features related to the combination of specific inputs and responses.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 14,
        "Sent ID": "",
        "Spoken words": "basically whether count appeal conversation okay point features complete check paper 'll 'll 'll",
        "Sent i": 66,
        "Sent Text": "while we are currently applying this to complete conversations (i.e., the classification is done on the whole conversation), some of the features examined here could likely be used to detect egregious conversations as they were unfolding in real time.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 8,
        "Sent ID": "",
        "Spoken words": "begin agents response first week ease called repeating",
        "Sent i": 72,
        "Sent Text": "when the agent starts losing the context of a conversation, fails in understanding the customer intention, or keeps repeating the same responses, the illusion of conversing with a human is lost and the conversation may become extremely annoying.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 8,
        "Sent ID": "",
        "Spoken words": "sponson analysis basically aims find many time agents",
        "Sent i": 75,
        "Sent Text": "accurate intent detection is thus a fundamental characteristic of well-trained virtual agents, and incorrect intent analysis is reported as the leading cause of user dissatisfaction (sarikaya, 2017).",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 6,
        "Sent ID": "",
        "Spoken words": "keep rephrasing saying 're response similarly",
        "Sent i": 77,
        "Sent Text": "is often used to detect intents, its probabilistic behavior can cause the agent to repeat the same (or semantically similar) response over and over again, despite the user’s attempt to rephrase the same intent.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 17,
        "Sent ID": "",
        "Spoken words": "spahn 's order calculate sauna representing sentence leveraging buildings sentence using cause similarity find similar similar sentences",
        "Sent i": 80,
        "Sent Text": "we represented each sentence by averaging the pre-trained embeddings5 of each word in the sentence, calculating the cosine similarity between the representations.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 17,
        "Sent ID": "",
        "Spoken words": "set feature second feature call unsupported intent analysis basically means ball n't use supporting intent usually answer",
        "Sent i": 86,
        "Sent Text": "we extracted the possible variants of the unsupported intent messages directly from the system, and later matched them with the agent responses from the logs.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 15,
        "Sent ID": "",
        "Spoken words": "something like like 'm trained something similar okay next feature coming customers site point done",
        "Sent i": 87,
        "Sent Text": "from the customer’s point of view, an ineffective interaction with a virtual agent is clearly undesirable.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 10,
        "Sent ID": "",
        "Spoken words": "customer may want could behavioral cues first family 's emotion",
        "Sent i": 89,
        "Sent Text": "these efforts can appear as behavioral cues in the customer’s inputs, and include emotions, repetitions, and more.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 9,
        "Sent ID": "",
        "Spoken words": "analysis saw example earlier real example discussed actually morning",
        "Sent i": 90,
        "Sent Text": "we used the following customer analysis in our model.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 36,
        "Sent ID": "",
        "Spoken words": "emotion really important seems one causes lead lead egregious conversation looking different behavior emotion looking big online emotions example max negative emotions also looking variation conversation ever going emotions conversation compared pick specific utterance done looking",
        "Sent i": 99,
        "Sent Text": "we focused on negative emotions (denoted as neg emo) to identify turns with a negative emotional peak (i.e., single utterances that carried high negative emotional state), as well as to estimate the aggregated negative emotion throughout the conversation (i.e., the averaged negative emotion intensity).",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 19,
        "Sent ID": "",
        "Spoken words": "rephrasing analysis equivalent say trying capture many times efforts customer trying rephrase agents well hopefully understand also another feature",
        "Sent i": 102,
        "Sent Text": "note that we used the positive emotions as a filter for other customer features, such as the rephrasing analysis.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 11,
        "Sent ID": "",
        "Spoken words": "asking human agents want make clear 's perfectly okay ask agent",
        "Sent i": 104,
        "Sent Text": "in examining the conversation logs, we noticed that it is not unusual to find a customer asking to be transferred to a human agent.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 15,
        "Sent ID": "",
        "Spoken words": "however cases 's one cases example customizable human also carreon negative emotions taken care okay",
        "Sent i": 108,
        "Sent Text": "the assumption is that single word (unigram) sentences are probably short customer responses (e.g., no, yes, thanks, okay), which in most cases do not contribute to the egregiousness of the conversation.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 10,
        "Sent ID": "",
        "Spoken words": "finally looking interaction agent customer agent first group feature looking",
        "Sent i": 110,
        "Sent Text": "we also looked at features across conversation utterance-response pairs in order to capture a more complete picture of the interac- tion between the customer and the virtual agent.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 31,
        "Sent ID": "",
        "Spoken words": "behavior inputs customer phones something like 'm trained give example civil third one call long sentences maybe imagine starting write long sentence explaining question something need enough use spend quite lot",
        "Sent i": 108,
        "Sent Text": "the assumption is that single word (unigram) sentences are probably short customer responses (e.g., no, yes, thanks, okay), which in most cases do not contribute to the egregiousness of the conversation.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 3,
        "Sent ID": "",
        "Spoken words": "time fourth efforts",
        "Sent i": 116,
        "Sent Text": "these features are summarized in the last part of table 1.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 20,
        "Sent ID": "",
        "Spoken words": "press enter immediately got 'm turn could closely high frustration customer later group cause section looking also customer aside freezing",
        "Sent i": 117,
        "Sent Text": "we also calculated the similarity between the customer’s turn and the virtual agent’s response in cases of customer rephrasing.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 4,
        "Sent ID": "",
        "Spoken words": "analysis example getting results",
        "Sent i": 118,
        "Sent Text": "this analysis aims to capture the reason for the customer rephrasing.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 5,
        "Sent ID": "",
        "Spoken words": "similar results agents basically means",
        "Sent i": 127,
        "Sent Text": "both agents are using similar underlying conversation engines, each embedded in a larger system with its own unique business logic.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 16,
        "Sent ID": "",
        "Spoken words": "customer trying phrase room input agent keep getting wrong thing keep turn wrong customer expected conversation",
        "Sent i": 129,
        "Sent Text": "each system logs conversations, and each conversation is a sequence of tuples, where each tuple consists of {conversation id, turn id, customer input, agent response}.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 15,
        "Sent ID": "",
        "Spoken words": "lens feature okay setting sample full eleven hundred conversation company another two hundred company 's",
        "Sent i": 136,
        "Sent Text": "this sample included 1100 and 200 conversations for company a and company b respectively.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 27,
        "Sent ID": "",
        "Spoken words": "conversation give give hci experts judge using guideline conversation exploded mute extra ordinarily bad ways conversations like see human jump save conversation okay like superman something like",
        "Sent i": 139,
        "Sent Text": "given the full conversation, each judge tagged whether the conversation was egregious or not following this guideline: “conversations which are extraordinarily bad in some way, those conversations where you’d like to see a human jump in and save the conversation”.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 8,
        "Sent ID": "",
        "Spoken words": "delay delay delay ability judges high around point",
        "Sent i": 141,
        "Sent Text": "the interrater reliability between all judges, measured by cohen’s kappa, was 0.72 which indicates high level agreement.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 13,
        "Sent ID": "",
        "Spoken words": "two okay run actually non companies around eight percent conversation doug egregious 'm",
        "Sent i": 140,
        "Sent Text": "we generated true binary labels by considering a conversation to be egregious if at least three of the four judges agreed.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 10,
        "Sent ID": "",
        "Spoken words": "tools looking also implemented focus based whether compel due first",
        "Sent i": 144,
        "Sent Text": "we also implemented two baseline models, rule-based and text-based, as follows: rule-based.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 2,
        "Sent ID": "",
        "Spoken words": "model text",
        "Sent i": 147,
        "Sent Text": "a model that was trained to predict egregiousness given the conversation’s text (all customer and agent’s text dur- 8judges that are hci experts and have experience in designing conversational agents systems.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 15,
        "Sent ID": "",
        "Spoken words": "based model looked unique grimes feature lexicon coming emotion emotional features door based looking simple",
        "Sent i": 148,
        "Sent Text": "this model was implemented using state-of-the-art textual features as in (herzig et al., 2017).",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 8,
        "Sent ID": "",
        "Spoken words": "agent response 'm trained customer asking agent finally",
        "Sent i": 147,
        "Sent Text": "a model that was trained to predict egregiousness given the conversation’s text (all customer and agent’s text dur- 8judges that are hci experts and have experience in designing conversational agents systems.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 1,
        "Sent ID": "",
        "Spoken words": "implemented",
        "Sent i": 148,
        "Sent Text": "this model was implemented using state-of-the-art textual features as in (herzig et al., 2017).",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 3,
        "Sent ID": "",
        "Spoken words": "class using v",
        "Sent i": 151,
        "Sent Text": "since class distribution is unbalanced, we evaluated classification performance by using precision (p), recall (r) and f1-score (f) for each class.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 1,
        "Sent ID": "",
        "Spoken words": "svm",
        "Sent i": 152,
        "Sent Text": "the egr classifier was implemented using an svm with a linear kernel9.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 7,
        "Sent ID": "",
        "Spoken words": "okay results okay look f one school",
        "Sent i": 153,
        "Sent Text": "table 2 depicts the classification results for both classes and the three models we explored.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 12,
        "Sent ID": "",
        "Spoken words": "see egregious classifiers outperforming bass baseline approach around forty percent eighty percent",
        "Sent i": 154,
        "Sent Text": "the egr model significantly outperformed both baselines10.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 9,
        "Sent ID": "",
        "Spoken words": "text based think also interesting look precision seems least",
        "Sent i": 155,
        "Sent Text": "specifically, for the egregious class, the precision obtained by the text-based and egr models were similar.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 8,
        "Sent ID": "",
        "Spoken words": "text based approaches capture send egregious using text",
        "Sent i": 156,
        "Sent Text": "this indicates that the text analyzed by both models encodes some information about egregiousness.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 14,
        "Sent ID": "",
        "Spoken words": "features interesting continue feature sets contribution analyses basically heading incremental time one different sets",
        "Sent i": 159,
        "Sent Text": "to better understand the contributions of different sets of features to our egr model, we examined various features in an incremental fashion.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 7,
        "Sent ID": "",
        "Spoken words": "feature starting agents features adding customer finally",
        "Sent i": 160,
        "Sent Text": "based on the groups of feature sets that we defined in section 3, we tested the performance of different group combinations, added in the following order: agent, customer and customer-agent interactions.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 23,
        "Sent ID": "",
        "Spoken words": "also get see gray column adding also goodwill gave us highest quality also interesting features coming customer along informative respect detecting egregious okay",
        "Sent i": 164,
        "Sent Text": "the figure also suggests that the most informative group in terms of prediction ability is the customer group.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 21,
        "Sent ID": "",
        "Spoken words": "look main remember company conversations trying data using company data n't musician note tuning destroyed simple simply company data look score",
        "Sent i": 167,
        "Sent Text": "for this task, we utilized the 200 annotated conversations of company b as test data, and experimented with the different models, trained on company a’s data.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 3,
        "Sent ID": "",
        "Spoken words": "also somehow expected",
        "Sent i": 168,
        "Sent Text": "the rule-based baseline does not require training, of course, and could be applied directly.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 19,
        "Sent ID": "",
        "Spoken words": "degradation nine percent still seems able detect 'd also nice seize annoyance nice look performance text based much lower",
        "Sent i": 169,
        "Sent Text": "table 3 summarizes the results showing that the performance of the egr model is relatively stable (w.r.t the model’s performance when it was trained and tested on the same domain), with a degradation of only 9% in f1-score11.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 10,
        "Sent ID": "",
        "Spoken words": "used fact text feature allows tied main trained okay finally",
        "Sent i": 171,
        "Sent Text": "this may occur since textual features are closely tied to the training domain.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 37,
        "Sent ID": "",
        "Spoken words": "mom customer phrasing analysis inspired works saikai un sunal wanted idea understand difference reasons customer phrasing setting use heard systems little bit differently stuff problems problems related setting idea turn analyze whole distribution different egregious angry class",
        "Sent i": 172,
        "Sent Text": "inspired by (sarikaya, 2017; sano et al., 2017) we analyzed the customer rephrasing motivations for both the egregious and the non-egregious classes.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 6,
        "Sent ID": "",
        "Spoken words": "first time always l coming called",
        "Sent i": 173,
        "Sent Text": "first, we detected customer rephrasing as described in section 3.2.1, and then assigned to each its motivation.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 70,
        "Sent ID": "",
        "Spoken words": "basically intent detected correctly means agents response semantically file customer expected able coming limitation language generation limitation 's item intent section score customer satisfied two got agents example could agents going speak specific thing got us may broad use 's needs last elway 's 'll come dunn support intent basically 'm trained data supported agent look distribution good gorgeous see dumb much unsupported intent previous one error also lg reduction",
        "Sent i": 174,
        "Sent Text": "specifically, in our setting, the relevant motivations are12: (1) natural language understanding (nlu) error - the agent’s intent detection is wrong, and thus the agent’s response is semantically far from the customer’s turn; (2) language generation (lg) limitation - the intent is detected correctly, but the customer is not satisfied by the response (for example, the response was too generic); (3) unsupported intent error - the customer’s intent is not supported by the agent.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 15,
        "Sent ID": "",
        "Spoken words": "heiau non gregis one think get indicates customer tolerance blow blames get feedback agent time",
        "Sent i": 175,
        "Sent Text": "in order to detect nlu errors, we measured the similarity between the first customer turn (before the rephrasing) and the agent response.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 4,
        "Sent ID": "",
        "Spoken words": "actually understand case system",
        "Sent i": 181,
        "Sent Text": "this indicates that customers are more tolerant of cases where the system understood their intent, but the response is not exactly what they expected, rather than cases where the system’s response was “not trained”.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 13,
        "Sent ID": "",
        "Spoken words": "things ask thus conversation getting egregious fast also look arm also percentage course",
        "Sent i": 183,
        "Sent Text": "we further investigated why the egr model was better at identifying egregious conversations (i.e., its recall was higher compared to the baseline models).",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 1,
        "Sent ID": "",
        "Spoken words": "due",
        "Sent i": 185,
        "Sent Text": "those conversations were particularly prevalent with the agent’s difficulty to identify correctly the user’s intent due to nlu errors or lg limitation.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 7,
        "Sent ID": "",
        "Spoken words": "weight 's line 's annual company okay",
        "Sent i": 187,
        "Sent Text": "in addition, the customer intents that appeared in those conversations were very diverse.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 14,
        "Sent ID": "",
        "Spoken words": "conclude walker show detect egregious conversation using feature coming agent customer direction also feature",
        "Sent i": 189,
        "Sent Text": "in this paper, we have shown how it is possible to detect egregious conversations using a combination of customer utterances, agent responses, and customer-agent interactional features.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 9,
        "Sent ID": "",
        "Spoken words": "whole bust first main future work consul first want",
        "Sent i": 191,
        "Sent Text": "in this context, future work includes collecting more data and using neural approaches (e.g., rnn, cnn) for analysis, validating our models on a range of domains beyond the two explored here.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 11,
        "Sent ID": "",
        "Spoken words": "every time n't want waiting end call conversation plan real time",
        "Sent i": 192,
        "Sent Text": "we also plan to extend the work to detect egregious conversations in real time (e.g., for escalating to a human operators), and create log analysis tools to analyze the root causes of egregious conversations and suggest possible remedies.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 5,
        "Sent ID": "",
        "Spoken words": "want collect data look approaches",
        "Sent i": 191,
        "Sent Text": "in this context, future work includes collecting more data and using neural approaches (e.g., rnn, cnn) for analysis, validating our models on a range of domains beyond the two explored here.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 26,
        "Sent ID": "",
        "Spoken words": "order useful also integrates real alice 's tools explained root cause egregious conversations high thanks great holiday foundation lose track many feature dollar contacts 'm wondering",
        "Sent i": 192,
        "Sent Text": "we also plan to extend the work to detect egregious conversations in real time (e.g., for escalating to a human operators), and create log analysis tools to analyze the root causes of egregious conversations and suggest possible remedies.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 24,
        "Sent ID": "",
        "Spoken words": "type feature important lie compositional lands big data tenet repeating repented state repeating imports may help complete task 'm wondering tapley feature important expected",
        "Sent i": 191,
        "Sent Text": "in this context, future work includes collecting more data and using neural approaches (e.g., rnn, cnn) for analysis, validating our models on a range of domains beyond the two explored here.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 11,
        "Sent ID": "",
        "Spoken words": "'d last could n't hear last part repeat last also recall",
        "Sent i": 192,
        "Sent Text": "we also plan to extend the work to detect egregious conversations in real time (e.g., for escalating to a human operators), and create log analysis tools to analyze the root causes of egregious conversations and suggest possible remedies.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 3,
        "Sent ID": "",
        "Spoken words": "used three three",
        "Sent i": 191,
        "Sent Text": "in this context, future work includes collecting more data and using neural approaches (e.g., rnn, cnn) for analysis, validating our models on a range of domains beyond the two explored here.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 15,
        "Sent ID": "",
        "Spoken words": "feature sets right first ones extracted agent put segments customer decline action features many features",
        "Sent i": 189,
        "Sent Text": "in this paper, we have shown how it is possible to detect egregious conversations using a combination of customer utterances, agent responses, and customer-agent interactional features.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 3,
        "Sent ID": "",
        "Spoken words": "right 'm wondering",
        "Sent i": 190,
        "Sent Text": "as explained, the goal of this work is to give developers of automated agents tools to detect and then solve problems cre- ated by exceptionally bad conversations.",
        "GT": 0,
        "Backg": 0
    },
    {
        "Duration": 19,
        "Sent ID": "",
        "Spoken words": "type features important one okay actually 's appear system analysis get featuring within group 's part work discuss line",
        "Sent i": 191,
        "Sent Text": "in this context, future work includes collecting more data and using neural approaches (e.g., rnn, cnn) for analysis, validating our models on a range of domains beyond the two explored here.",
        "GT": 0,
        "Backg": 0
    }
]