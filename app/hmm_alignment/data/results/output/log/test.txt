Logging to file: data/results/output/log/test.txt

--- paper 0: test.txt

HmmArticleConfig:
sent_sent_similarity_wordwise: True
debug_mode: False
word_embed_fname: glove.6B/glove.6B.300d.txt
allow_backward_steps: True
trans_prob_decay: 0.75
wmd: False
section_id_related_work: None
labeled_data_mode: False
transcript_word_level_mode: True
similarity_fname: data/results/similarity/test.npy
emis_prob_subtruct_min_factor: 0.8
lower_case: True
backward_prob_factor: 2
section_id_intro: 0
backg_stay_prob: None
auto_stay_prob_first_approach: True
remove_stop_words: True
backg_word_count_fname: None
stay_prob: None
hmm_algo: HmmAlgo.VITERBI_0

the following stop words and punctuations will be removed from article text and transcript:
{"'", 'wouldn', 're', "haven't", 'own', 'have', 'against', 'ain', 'in', 'as', 'that', 'on', 'don', 'd', '>', 'whom', "didn't", 'when', 'weren', 'doesn', 'before', 'won', 'such', 'why', "shouldn't", 'now', 'there', 'both', 'some', "doesn't", 'myself', 'should', "won't", 'wasn', 'her', 'but', 'they', 'then', 'yourselves', 'do', 'o', '"', 'of', 'down', 'out', 'ourselves', '~', 'we', 'what', 'does', 'just', 'few', 'to', '!', 'be', 'she', "don't", 'which', 'is', 'those', 'about', "shan't", 'these', '+', "weren't", 's', '[', "hasn't", 'was', '^', "that'll", 'if', 'ma', 'until', '*', 'his', 'yourself', ']', "you're", 'into', "hadn't", 'for', 'it', 't', 'our', '_', 'from', "you've", 'am', '\\', 'through', 'more', 'this', 'mightn', 'above', 'during', 'himself', 'how', 'same', 'under', 'nor', 'you', "aren't", 'an', 'most', 've', '-', 'or', 'very', 'them', 'over', 'him', 'where', "couldn't", "needn't", 'below', "it's", 'than', 'aren', 'had', 'a', 'with', 'up', '=', 'at', '&', 'my', 'being', '}', 'your', 'y', 'me', 'too', '#', 'while', 'm', 'no', 'mustn', '<', ',', 'herself', 'further', 'hadn', 'itself', "she's", 'off', 'so', 'haven', "isn't", 'couldn', 'any', 'yours', 'can', 'each', 'are', "mustn't", 'having', '`', 'because', 'their', 'will', ':', "you'd", 'who', 'the', ')', 'i', 'been', '@', 'he', 'after', 'again', 'hers', 'hasn', 'did', '?', 'by', '|', "mightn't", 'its', 'themselves', 'other', 'once', '/', 'll', 'only', 'isn', 'shan', "wasn't", 'theirs', 'and', "wouldn't", 'not', 'needn', "you'll", '.', '(', 'shouldn', "should've", '%', 'has', 'between', '{', 'here', 'doing', ';', 'didn', 'were', '$', 'ours', 'all'}
total number of sentences in the transcript: 77
total number of tokens in the whole transcript: 1157
vocabulary size: 542
original number of article sentences: 193
after removing sentences of Related Work section, number of article sentences is now: 193
intro_sent_indices was empty. it was set to the first 20 sentences
n_observations: 542
n_article_sentences: 193
n_states: 193
stay_prob: 0.28
[26.10|23:33:51] reading file: glove.6B/glove.6B.300d.txt
[26.10|23:34:18] done
dim: 300
num_words: 400000
[26.10|23:34:19] w2v dimension: 300
word not found: chatbots
word not found: chatbots
word not found: 20201
word not found: chatbots
word not found: 20202
word not found: chatbots
word not found: off-the-mark
word not found: chatbots
word not found: egregious3
word not found: chatbots
word not found: chatbot
word not found: chatbots
word not found: chatbot4
word not found: chatbot
word not found: chatbot
word not found: ’
word not found: “
word not found: ”
word not found: chatbot
word not found: “
word not found: ’
word not found: ”
word not found: “
word not found: ’
word not found: ”
word not found: chatbot
word not found: chatbot
word not found: chatbot
word not found: chatbot
word not found: ”
word not found: ”
word not found: ”
word not found: ”
word not found: chatbot
word not found: customer-agent
word not found: egregiousness
word not found: hajdinjak
word not found: mihelic
word not found: kiseleva
word not found: 2016b
word not found: ’
word not found: ’
word not found: chatbot
word not found: simi-
word not found: larly
word not found: enduser
word not found: ’
word not found: multimodel
word not found: gnewuch
word not found: chatbots
word not found: chatbots
word not found: chatbots
word not found: gnewuch
word not found: tangibility
word not found: “
word not found: ”
word not found: “
word not found: non-egregious
word not found: ”
word not found: egre-
word not found: gious
word not found: ’
word not found: customer-agent
word not found: krämer
word not found: ’
word not found: ’
word not found: ’
word not found: ’
word not found: klüwer
word not found: ’
word not found: ’
word not found: pre-trained
word not found: embeddings5
word not found: value6
word not found: “
word not found: ’
word not found: ”
word not found: ’
word not found: zeithaml
word not found: ’
word not found: rephrases
word not found: ’
word not found: ’
word not found: 3.1.1
word not found: value6
word not found: rephrases
word not found: ’
word not found: ’
word not found: online7
word not found: ’
word not found: “
word not found: ”
word not found: rychalski
word not found: unigram
word not found: egregiousness
word not found: utterance-response
word not found: interac-
word not found: “
word not found: ”
word not found: ’
word not found: ’
word not found: ’
word not found: ’
word not found: ’
word not found: ’
word not found: ’
word not found: ’
word not found: ’
word not found: “
word not found: ”
word not found: “
word not found: ”
word not found: “
word not found: non-egregious
word not found: ”
word not found: ’
word not found: ’
word not found: ’
word not found: judges8
word not found: “
word not found: ’
word not found: ”
word not found: interrater
word not found: ’
word not found: “
word not found: ”
word not found: ’
word not found: ’
word not found: egregiousness
word not found: ’
word not found: ’
word not found: dur-
word not found: 8judges
word not found: crossvalidation
word not found: ’
word not found: ’
word not found: f1-score
word not found: kernel9
word not found: baselines10
word not found: egregiousness
word not found: f1-score
word not found: customer-agent
word not found: ’
word not found: w.r.t
word not found: ’
word not found: f1-score11
word not found: f1-score
word not found: non-egregious
word not found: 3.2.1
word not found: are12
word not found: ’
word not found: ’
word not found: ’
word not found: ’
word not found: ≥
word not found: 3.1.2
word not found: non-egregious
word not found: ’
word not found: “
word not found: ”
word not found: ’
word not found: ’
word not found: customer-agent
word not found: cre-
word not found: ated
total number of times word not found: 165
[26.10|23:34:19] preparing similarities for emission probabilities...
  0%|          | 0/193 [00:00<?, ?it/s]  1%|          | 1/193 [00:00<01:45,  1.82it/s]  1%|1         | 2/193 [00:01<01:40,  1.89it/s]  2%|1         | 3/193 [00:01<02:03,  1.54it/s]  2%|2         | 4/193 [00:02<01:52,  1.68it/s]  3%|2         | 5/193 [00:03<01:57,  1.61it/s]  3%|3         | 6/193 [00:03<01:50,  1.70it/s]  4%|3         | 7/193 [00:03<01:34,  1.96it/s]  4%|4         | 8/193 [00:04<01:30,  2.05it/s]  5%|4         | 9/193 [00:04<01:16,  2.40it/s]  5%|5         | 10/193 [00:04<01:11,  2.57it/s]  6%|5         | 11/193 [00:05<01:17,  2.34it/s]  6%|6         | 12/193 [00:05<01:04,  2.79it/s]  7%|6         | 13/193 [00:06<01:04,  2.79it/s]  7%|7         | 14/193 [00:06<01:21,  2.19it/s]  8%|7         | 15/193 [00:07<01:18,  2.26it/s]  8%|8         | 16/193 [00:07<01:12,  2.45it/s]  9%|8         | 17/193 [00:07<01:03,  2.78it/s]  9%|9         | 18/193 [00:08<01:07,  2.60it/s] 10%|9         | 19/193 [00:08<01:16,  2.28it/s] 10%|#         | 20/193 [00:09<01:20,  2.15it/s] 11%|#         | 21/193 [00:09<01:17,  2.22it/s] 11%|#1        | 22/193 [00:10<01:20,  2.12it/s] 12%|#1        | 23/193 [00:10<01:12,  2.34it/s] 12%|#2        | 24/193 [00:10<01:15,  2.23it/s] 13%|#2        | 25/193 [00:11<01:26,  1.94it/s] 13%|#3        | 26/193 [00:12<01:25,  1.96it/s] 14%|#3        | 27/193 [00:12<01:15,  2.21it/s] 15%|#4        | 28/193 [00:13<01:32,  1.78it/s] 15%|#5        | 29/193 [00:13<01:31,  1.79it/s] 16%|#5        | 30/193 [00:14<01:38,  1.65it/s] 16%|#6        | 31/193 [00:15<01:54,  1.42it/s] 17%|#6        | 32/193 [00:15<01:27,  1.84it/s] 17%|#7        | 33/193 [00:16<01:18,  2.05it/s] 18%|#7        | 34/193 [00:16<01:03,  2.48it/s] 18%|#8        | 35/193 [00:16<00:52,  3.01it/s] 19%|#8        | 36/193 [00:17<01:04,  2.42it/s] 19%|#9        | 37/193 [00:17<01:02,  2.50it/s] 20%|#9        | 38/193 [00:18<01:35,  1.63it/s] 20%|##        | 39/193 [00:18<01:13,  2.09it/s] 21%|##        | 40/193 [00:18<01:02,  2.45it/s] 21%|##1       | 41/193 [00:19<00:58,  2.60it/s] 22%|##1       | 42/193 [00:20<01:23,  1.81it/s] 22%|##2       | 43/193 [00:20<01:28,  1.69it/s] 23%|##2       | 44/193 [00:21<01:17,  1.91it/s] 23%|##3       | 45/193 [00:21<01:17,  1.92it/s] 24%|##3       | 46/193 [00:22<01:09,  2.11it/s] 24%|##4       | 47/193 [00:22<01:11,  2.04it/s] 25%|##4       | 48/193 [00:23<01:09,  2.08it/s] 25%|##5       | 49/193 [00:23<01:02,  2.30it/s] 26%|##5       | 50/193 [00:24<01:09,  2.04it/s] 26%|##6       | 51/193 [00:24<01:30,  1.58it/s] 27%|##6       | 52/193 [00:25<01:18,  1.80it/s] 27%|##7       | 53/193 [00:26<01:26,  1.62it/s] 28%|##7       | 54/193 [00:26<01:23,  1.66it/s] 28%|##8       | 55/193 [00:27<01:18,  1.77it/s] 29%|##9       | 56/193 [00:27<01:21,  1.69it/s] 30%|##9       | 57/193 [00:28<01:19,  1.70it/s] 30%|###       | 58/193 [00:28<01:14,  1.82it/s] 31%|###       | 59/193 [00:29<01:22,  1.62it/s] 31%|###1      | 60/193 [00:30<01:15,  1.76it/s] 32%|###1      | 61/193 [00:30<01:21,  1.62it/s] 32%|###2      | 62/193 [00:31<01:08,  1.93it/s] 33%|###2      | 63/193 [00:31<01:09,  1.86it/s] 33%|###3      | 64/193 [00:32<01:08,  1.89it/s] 34%|###3      | 65/193 [00:32<01:01,  2.08it/s] 34%|###4      | 66/193 [00:32<00:53,  2.37it/s] 35%|###4      | 67/193 [00:33<01:06,  1.89it/s] 35%|###5      | 68/193 [00:34<01:12,  1.73it/s] 36%|###5      | 69/193 [00:34<01:00,  2.04it/s] 36%|###6      | 70/193 [00:35<01:09,  1.78it/s] 37%|###6      | 71/193 [00:35<00:55,  2.19it/s] 37%|###7      | 72/193 [00:36<01:01,  1.98it/s] 38%|###7      | 73/193 [00:37<01:11,  1.67it/s] 38%|###8      | 74/193 [00:37<01:06,  1.78it/s] 39%|###8      | 75/193 [00:37<01:02,  1.87it/s] 39%|###9      | 76/193 [00:38<01:10,  1.66it/s] 40%|###9      | 77/193 [00:39<01:00,  1.92it/s] 40%|####      | 78/193 [00:39<01:05,  1.76it/s] 41%|####      | 79/193 [00:39<00:53,  2.12it/s] 41%|####1     | 80/193 [00:40<00:52,  2.15it/s] 42%|####1     | 81/193 [00:40<00:48,  2.31it/s] 42%|####2     | 82/193 [00:41<00:41,  2.66it/s] 43%|####3     | 83/193 [00:41<00:44,  2.46it/s] 44%|####3     | 84/193 [00:41<00:46,  2.35it/s] 44%|####4     | 85/193 [00:42<00:38,  2.79it/s] 45%|####4     | 86/193 [00:42<00:44,  2.39it/s] 45%|####5     | 87/193 [00:43<00:47,  2.22it/s] 46%|####5     | 88/193 [00:43<00:44,  2.37it/s] 46%|####6     | 89/193 [00:44<00:52,  1.98it/s] 47%|####6     | 90/193 [00:44<00:47,  2.17it/s] 47%|####7     | 91/193 [00:44<00:39,  2.61it/s] 48%|####7     | 92/193 [00:45<00:35,  2.85it/s] 48%|####8     | 93/193 [00:45<00:36,  2.73it/s] 49%|####8     | 94/193 [00:45<00:35,  2.82it/s] 49%|####9     | 95/193 [00:46<00:38,  2.54it/s] 50%|####9     | 96/193 [00:46<00:31,  3.07it/s] 50%|#####     | 97/193 [00:46<00:33,  2.85it/s] 51%|#####     | 98/193 [00:47<00:38,  2.47it/s] 51%|#####1    | 99/193 [00:47<00:39,  2.40it/s] 52%|#####1    | 100/193 [00:49<01:00,  1.53it/s] 52%|#####2    | 101/193 [00:49<00:59,  1.55it/s] 53%|#####2    | 102/193 [00:50<00:48,  1.87it/s] 53%|#####3    | 103/193 [00:50<00:43,  2.07it/s] 54%|#####3    | 104/193 [00:51<00:52,  1.70it/s] 54%|#####4    | 105/193 [00:51<00:47,  1.83it/s] 55%|#####4    | 106/193 [00:51<00:41,  2.10it/s] 55%|#####5    | 107/193 [00:52<00:47,  1.81it/s] 56%|#####5    | 108/193 [00:53<00:42,  1.99it/s] 56%|#####6    | 109/193 [00:53<00:44,  1.89it/s] 57%|#####6    | 110/193 [00:54<00:41,  1.99it/s] 58%|#####7    | 111/193 [00:54<00:42,  1.91it/s] 58%|#####8    | 112/193 [00:54<00:36,  2.22it/s] 59%|#####8    | 113/193 [00:55<00:37,  2.13it/s] 59%|#####9    | 114/193 [00:55<00:33,  2.36it/s] 60%|#####9    | 115/193 [00:56<00:29,  2.63it/s] 60%|######    | 116/193 [00:56<00:27,  2.85it/s] 61%|######    | 117/193 [00:56<00:24,  3.14it/s] 61%|######1   | 118/193 [00:57<00:26,  2.81it/s] 62%|######1   | 119/193 [00:57<00:23,  3.08it/s] 62%|######2   | 120/193 [00:58<00:32,  2.23it/s] 63%|######2   | 121/193 [00:58<00:32,  2.20it/s] 63%|######3   | 122/193 [00:58<00:31,  2.28it/s] 64%|######3   | 123/193 [00:59<00:26,  2.61it/s] 64%|######4   | 124/193 [00:59<00:30,  2.26it/s] 65%|######4   | 125/193 [01:00<00:31,  2.16it/s] 65%|######5   | 126/193 [01:00<00:29,  2.24it/s] 66%|######5   | 127/193 [01:01<00:32,  2.01it/s] 66%|######6   | 128/193 [01:01<00:31,  2.03it/s] 67%|######6   | 129/193 [01:02<00:33,  1.91it/s] 67%|######7   | 130/193 [01:03<00:35,  1.78it/s] 68%|######7   | 131/193 [01:03<00:28,  2.18it/s] 68%|######8   | 132/193 [01:03<00:30,  1.99it/s] 69%|######8   | 133/193 [01:04<00:27,  2.18it/s] 69%|######9   | 134/193 [01:04<00:28,  2.05it/s] 70%|######9   | 135/193 [01:05<00:25,  2.25it/s] 70%|#######   | 136/193 [01:05<00:21,  2.68it/s] 71%|#######   | 137/193 [01:05<00:20,  2.72it/s] 72%|#######1  | 138/193 [01:06<00:21,  2.52it/s] 72%|#######2  | 139/193 [01:06<00:18,  2.96it/s] 73%|#######2  | 140/193 [01:07<00:25,  2.06it/s] 73%|#######3  | 141/193 [01:07<00:25,  2.06it/s] 74%|#######3  | 142/193 [01:08<00:23,  2.18it/s] 74%|#######4  | 143/193 [01:08<00:23,  2.11it/s] 75%|#######4  | 144/193 [01:08<00:19,  2.45it/s] 75%|#######5  | 145/193 [01:09<00:19,  2.52it/s] 76%|#######5  | 146/193 [01:09<00:20,  2.25it/s] 76%|#######6  | 147/193 [01:10<00:19,  2.31it/s] 77%|#######6  | 148/193 [01:10<00:22,  2.03it/s] 77%|#######7  | 149/193 [01:11<00:20,  2.16it/s] 78%|#######7  | 150/193 [01:11<00:20,  2.08it/s] 78%|#######8  | 151/193 [01:12<00:22,  1.84it/s] 79%|#######8  | 152/193 [01:12<00:22,  1.82it/s] 79%|#######9  | 153/193 [01:13<00:18,  2.15it/s] 80%|#######9  | 154/193 [01:13<00:16,  2.31it/s] 80%|########  | 155/193 [01:13<00:13,  2.83it/s] 81%|########  | 156/193 [01:14<00:13,  2.78it/s] 81%|########1 | 157/193 [01:14<00:11,  3.07it/s] 82%|########1 | 158/193 [01:14<00:12,  2.70it/s] 83%|########2 | 160/193 [01:15<00:11,  2.86it/s] 83%|########3 | 161/193 [01:16<00:14,  2.21it/s] 84%|########3 | 162/193 [01:16<00:12,  2.56it/s] 84%|########4 | 163/193 [01:16<00:11,  2.62it/s] 85%|########4 | 164/193 [01:17<00:11,  2.53it/s] 85%|########5 | 165/193 [01:17<00:11,  2.52it/s] 86%|########6 | 166/193 [01:18<00:13,  2.08it/s] 87%|########6 | 167/193 [01:18<00:13,  1.91it/s] 87%|########7 | 168/193 [01:19<00:13,  1.84it/s] 88%|########7 | 169/193 [01:19<00:11,  2.10it/s] 88%|########8 | 170/193 [01:20<00:12,  1.88it/s] 89%|########8 | 171/193 [01:20<00:11,  1.93it/s] 89%|########9 | 172/193 [01:21<00:09,  2.11it/s] 90%|########9 | 173/193 [01:21<00:09,  2.03it/s] 90%|######### | 174/193 [01:22<00:08,  2.24it/s] 91%|######### | 175/193 [01:23<00:14,  1.24it/s] 91%|#########1| 176/193 [01:24<00:12,  1.40it/s] 92%|#########1| 177/193 [01:25<00:11,  1.39it/s] 92%|#########2| 178/193 [01:25<00:08,  1.72it/s] 93%|#########2| 179/193 [01:25<00:07,  1.84it/s] 93%|#########3| 180/193 [01:26<00:06,  2.08it/s] 94%|#########3| 181/193 [01:27<00:07,  1.59it/s] 94%|#########4| 182/193 [01:27<00:06,  1.64it/s] 95%|#########4| 183/193 [01:28<00:06,  1.55it/s] 95%|#########5| 184/193 [01:28<00:05,  1.65it/s] 96%|#########5| 185/193 [01:29<00:04,  1.79it/s] 96%|#########6| 186/193 [01:29<00:03,  1.78it/s] 97%|#########6| 187/193 [01:30<00:03,  1.79it/s] 97%|#########7| 188/193 [01:30<00:02,  2.16it/s] 98%|#########7| 189/193 [01:31<00:02,  1.97it/s] 98%|#########8| 190/193 [01:31<00:01,  1.90it/s] 99%|#########8| 191/193 [01:32<00:01,  1.88it/s] 99%|#########9| 192/193 [01:33<00:00,  1.64it/s]100%|##########| 193/193 [01:34<00:00,  1.40it/s]100%|##########| 193/193 [01:34<00:00,  2.05it/s]
[26.10|23:35:53] created file: data/results/similarity/test.npy
[26.10|23:35:53] predict...
[26.10|23:36:04] done
predicted sequence summary:
   0:   21
   3:    7
   6:    9
   0:    8
   1:    5
   0:    8
   1:    5
   2:    2
   3:   15
   4:    4
  13:    4
  15:    3
  16:   36
  17:   13
  18:   40
  19:   16
  32:    9
  36:    9
  37:    5
  39:    2
  43:    4
  45:   19
  46:    2
  49:    7
  53:    3
  57:   11
  60:   26
  64:   21
  65:   12
  66:    6
  67:   22
  66:   14
  72:    8
  75:    8
  77:    6
  80:   17
  86:   17
  87:   15
  89:   10
  90:    9
  99:   36
 102:   19
 104:   11
 108:   15
 110:   10
 108:   31
 116:    3
 117:   20
 118:    4
 127:    5
 129:   16
 136:   15
 139:   27
 141:    8
 140:   13
 144:   10
 147:    2
 148:   15
 147:    8
 148:    1
 151:    3
 152:    1
 153:    7
 154:   12
 155:    9
 156:    8
 159:   14
 160:    7
 164:   23
 167:   21
 168:    3
 169:   19
 171:   10
 172:   37
 173:    6
 174:   70
 175:   15
 181:    4
 183:   13
 185:    1
 187:    7
 189:   14
 191:    9
 192:   11
 191:    5
 192:   26
 191:   24
 192:   11
 191:    3
 189:   15
 190:    3
 191:   19

num of predicted unique sentences: 77
predicted_seq_info: 
[{'Duration': 21, 'Sent ID': '', 'Spoken words': "okay high 'm name much show death present work detecting conversations customers virtual agents joint work ibm loving high fi yorktown", 'Sent i': 0, 'Sent Text': 'test automated conversational agents (chatbots) are becoming widely used for various tasks such as personal assistants or as customer service agents.', 'GT': 0, 'Backg': 0}, {'Duration': 7, 'Sent ID': '', 'Spoken words': 'okay one second okay sorry okay think', 'Sent i': 3, 'Sent Text': 'still, chatbots may behave extremely badly, leading to conversations so off-the-mark that only a human agent could step in and salvage them.', 'GT': 0, 'Backg': 0}, {'Duration': 9, 'Sent ID': '', 'Spoken words': 'stuff phoenician egregious egregious definition outstandingly bad shocking heard', 'Sent i': 6, 'Sent Text': 'in this paper we study detecting these egregious conversations that can arise in numerous ways.', 'GT': 0, 'Backg': 0}, {'Duration': 8, 'Sent ID': '', 'Spoken words': 'known interest using virtual agent increasing specifically prediction', 'Sent i': 0, 'Sent Text': 'test automated conversational agents (chatbots) are becoming widely used for various tasks such as personal assistants or as customer service agents.', 'GT': 0, 'Backg': 0}, {'Duration': 5, 'Sent ID': '', 'Spoken words': 'twenty twenty eighty percent businesses', 'Sent i': 1, 'Sent Text': 'recent studies project that 80% of businesses plan to use chatbots by 20201, and that chatbots will power 85% of customer service interactions by the year 20202.', 'GT': 0, 'Backg': 0}, {'Duration': 8, 'Sent ID': '', 'Spoken words': 'virtual agents even specifically look customer care main', 'Sent i': 0, 'Sent Text': 'test automated conversational agents (chatbots) are becoming widely used for various tasks such as personal assistants or as customer service agents.', 'GT': 0, 'Backg': 0}, {'Duration': 5, 'Sent ID': '', 'Spoken words': 'eighty five percent interactions provide', 'Sent i': 1, 'Sent Text': 'recent studies project that 80% of businesses plan to use chatbots by 20201, and that chatbots will power 85% of customer service interactions by the year 20202.', 'GT': 0, 'Backg': 0}, {'Duration': 2, 'Sent ID': '', 'Spoken words': 'powered virtual', 'Sent i': 2, 'Sent Text': 'this increasing usage is mainly due to advances in artificial intelligence and natural language processing (hirschberg and manning, 2015) along with increasingly capable chat development environments, leading to improvements in conversational richness and robustness.', 'GT': 0, 'Backg': 0}, {'Duration': 15, 'Sent ID': '', 'Spoken words': 'agents course good us however either experience know virtual agents might behave really bad lead', 'Sent i': 3, 'Sent Text': 'still, chatbots may behave extremely badly, leading to conversations so off-the-mark that only a human agent could step in and salvage them.', 'GT': 0, 'Backg': 0}, {'Duration': 4, 'Sent ID': '', 'Spoken words': 'loss customer loyalty even', 'Sent i': 4, 'Sent Text': 'consequences of these failures may include loss of customer goodwill and associated revenue, and even exposure to litigation if the failures can be shown to include fraudulent claims.', 'GT': 0, 'Backg': 0}, {'Duration': 4, 'Sent ID': '', 'Spoken words': 'ways use okay sir', 'Sent i': 13, 'Sent Text': 'the resulting customer frustration may not surface in easily detectable ways such as the appearance of all caps, shouting to a speech recognizer, or the use of profanity or extreme punctuation.', 'GT': 0, 'Backg': 0}, {'Duration': 3, 'Sent ID': '', 'Spoken words': 'real example conversation', 'Sent i': 15, 'Sent Text': 'consider, for example, the anonymized but representative conversation depicted in figure 1.', 'GT': 0, 'Backg': 0}, {'Duration': 36, 'Sent ID': '', 'Spoken words': "n't deal let take okay customer left agents right customer asking quotes travel wants know details agent kind understand telling consider purchased ticket customer interested n't want buy want know details agents actually missing gifts think", 'Sent i': 16, 'Sent Text': 'here the customer aims to understand the details of a flight ticket.', 'GT': 0, 'Backg': 0}, {'Duration': 13, 'Sent ID': '', 'Spoken words': 'already wants go next online lyor process rent cop customer asking rule person', 'Sent i': 17, 'Sent Text': 'in the first two turns, the chatbot misses the customer’s intentions, which leads to the customer asking “are you a real person?”.', 'GT': 0, 'Backg': 0}, {'Duration': 40, 'Sent ID': '', 'Spoken words': "response develop since assistant trained answer questions drivers get ask question customer trying start getting little bit annoyed ask specific question got sell agent picking answering 'm trained yet 'm still learning may want forget phase question time customer thing", 'Sent i': 18, 'Sent Text': 'the customer then tries to explain what went wrong, but the chatbot has insufficient exposure to this sort of utterance to provide anything but the default response (“i’m not trained on that”).', 'GT': 0, 'Backg': 0}, {'Duration': 16, 'Sent ID': '', 'Spoken words': "frustrated anger well pointless talk real life person answer n't currently live agents checked online okay", 'Sent i': 19, 'Sent Text': 'the response seems to upset the customer and leads to a request for a human agent, which is rejected by the system (“we don’t currently have live agents”).', 'GT': 0, 'Backg': 0}, {'Duration': 9, 'Sent ID': '', 'Spoken words': 'define egregious conversations okay course bunch well top elected', 'Sent i': 32, 'Sent Text': 'we review related work, then we formally define the methodology for detecting egregious conversations.', 'GT': 0, 'Backg': 0}, {'Duration': 9, 'Sent ID': '', 'Spoken words': 'book festal works todd looking computer complementary problems try', 'Sent i': 36, 'Sent Text': 'these works studied the complementary problem of detecting and measuring user satisfaction and engagement.', 'GT': 0, 'Backg': 0}, {'Duration': 5, 'Sent ID': '', 'Spoken words': 'maximize data previous work coming', 'Sent i': 37, 'Sent Text': 'early work by (walker et al., 1997, 2001) discussed a framework that maximizes the user satisfaction by considering measures such as number of inappropriate utterances, recognition rates, number of times user requests repetitions, number of turns per interaction, etc.', 'GT': 0, 'Backg': 0}, {'Duration': 2, 'Sent ID': '', 'Spoken words': 'mine systems', 'Sent i': 39, 'Sent Text': 'other works focus on predicting the user engagement in such systems.', 'GT': 0, 'Backg': 0}, {'Duration': 4, 'Sent ID': '', 'Spoken words': 'data use dialogue logo', 'Sent i': 43, 'Sent Text': 'in our work, we likewise use emotion analysis as predictive features for egregious conversation.', 'GT': 0, 'Backg': 0}, {'Duration': 19, 'Sent ID': '', 'Spoken words': 'specific setting late late stood two thousand seventeen somewhat thought trying study reason customers rephrasing different reasons affect satisfaction', 'Sent i': 45, 'Sent Text': 'specifically, in (sarikaya, 2017) they reported on how the different reasons affect the users’ satisfaction.', 'GT': 0, 'Backg': 0}, {'Duration': 2, 'Sent ID': '', 'Spoken words': 'dissatisfaction finally', 'Sent i': 46, 'Sent Text': 'in (sano et al., 2017) they focused on how to automatically predict the reason for user’s dissatisfaction using different features.', 'GT': 0, 'Backg': 0}, {'Duration': 7, 'Sent ID': '', 'Spoken words': 'also looking dialog break break downs walker', 'Sent i': 49, 'Sent Text': 'in (walker et al., 2000; hastie et al., 2002) the authors also looked for problems in a specific setting of spoken conversations.', 'GT': 0, 'Backg': 0}, {'Duration': 3, 'Sent ID': '', 'Spoken words': 'trying torrents level', 'Sent i': 53, 'Sent Text': 'in (steidl et al., 2004) they measured dialogue success at the turn level as a way of predicting the success of a conversation as a whole.', 'GT': 0, 'Backg': 0}, {'Duration': 11, 'Sent ID': '', 'Spoken words': 'try understand utterance break data japanese chat okay dealing would like', 'Sent i': 57, 'Sent Text': 'all these measures may serve as reasons for a conversation turning egregious, but none try to capture or predict it directly.', 'GT': 0, 'Backg': 0}, {'Duration': 26, 'Sent ID': '', 'Spoken words': 'sit extracted lead companies provide customer support using virtual agents company using similar line totally different domains one company business logic course arm system extract thousand', 'Sent i': 60, 'Sent Text': 'they found that a combination of exaggerated customer expectations along with a reduction in agent performance (e.g., failure to listen to the consumer, being too intrusive) caused customers to stop using such systems.', 'GT': 0, 'Backg': 0}, {'Duration': 21, 'Sent ID': '', 'Spoken words': 'conversations randomly see local distribution conversation never see conversation company much twice longer company okay recall thought try detect group conversation', 'Sent i': 64, 'Sent Text': 'the objective of this work is to reliably detect egregious conversations between a human and a virtual agent.', 'GT': 0, 'Backg': 0}, {'Duration': 12, 'Sent ID': '', 'Spoken words': 'treat problem binary classification problem target classes egregious awning gregis input classifieds', 'Sent i': 65, 'Sent Text': 'we treat this as a binary classification task, where the target classes are “egregious” and “non-egregious”.', 'GT': 0, 'Backg': 0}, {'Duration': 6, 'Sent ID': '', 'Spoken words': 'basically complete conversation classification done end', 'Sent i': 66, 'Sent Text': 'while we are currently applying this to complete conversations (i.e., the classification is done on the whole conversation), some of the features examined here could likely be used to detect egregious conversations as they were unfolding in real time.', 'GT': 0, 'Backg': 0}, {'Duration': 22, 'Sent ID': '', 'Spoken words': 'conversation struck dot three different feature sets conversation feature coming agent response customer input interaction feature customer agents also low feature context', 'Sent i': 67, 'Sent Text': 'to perform egregious conversation detection, features from both customer inputs and agent responses are extracted, together with features related to the combination of specific inputs and responses.', 'GT': 0, 'Backg': 0}, {'Duration': 14, 'Sent ID': '', 'Spoken words': "basically whether count appeal conversation okay point features complete check paper 'll 'll 'll", 'Sent i': 66, 'Sent Text': 'while we are currently applying this to complete conversations (i.e., the classification is done on the whole conversation), some of the features examined here could likely be used to detect egregious conversations as they were unfolding in real time.', 'GT': 0, 'Backg': 0}, {'Duration': 8, 'Sent ID': '', 'Spoken words': 'begin agents response first week ease called repeating', 'Sent i': 72, 'Sent Text': 'when the agent starts losing the context of a conversation, fails in understanding the customer intention, or keeps repeating the same responses, the illusion of conversing with a human is lost and the conversation may become extremely annoying.', 'GT': 0, 'Backg': 0}, {'Duration': 8, 'Sent ID': '', 'Spoken words': 'sponson analysis basically aims find many time agents', 'Sent i': 75, 'Sent Text': 'accurate intent detection is thus a fundamental characteristic of well-trained virtual agents, and incorrect intent analysis is reported as the leading cause of user dissatisfaction (sarikaya, 2017).', 'GT': 0, 'Backg': 0}, {'Duration': 6, 'Sent ID': '', 'Spoken words': "keep rephrasing saying 're response similarly", 'Sent i': 77, 'Sent Text': 'is often used to detect intents, its probabilistic behavior can cause the agent to repeat the same (or semantically similar) response over and over again, despite the user’s attempt to rephrase the same intent.', 'GT': 0, 'Backg': 0}, {'Duration': 17, 'Sent ID': '', 'Spoken words': "spahn 's order calculate sauna representing sentence leveraging buildings sentence using cause similarity find similar similar sentences", 'Sent i': 80, 'Sent Text': 'we represented each sentence by averaging the pre-trained embeddings5 of each word in the sentence, calculating the cosine similarity between the representations.', 'GT': 0, 'Backg': 0}, {'Duration': 17, 'Sent ID': '', 'Spoken words': "set feature second feature call unsupported intent analysis basically means ball n't use supporting intent usually answer", 'Sent i': 86, 'Sent Text': 'we extracted the possible variants of the unsupported intent messages directly from the system, and later matched them with the agent responses from the logs.', 'GT': 0, 'Backg': 0}, {'Duration': 15, 'Sent ID': '', 'Spoken words': "something like like 'm trained something similar okay next feature coming customers site point done", 'Sent i': 87, 'Sent Text': 'from the customer’s point of view, an ineffective interaction with a virtual agent is clearly undesirable.', 'GT': 0, 'Backg': 0}, {'Duration': 10, 'Sent ID': '', 'Spoken words': "customer may want could behavioral cues first family 's emotion", 'Sent i': 89, 'Sent Text': 'these efforts can appear as behavioral cues in the customer’s inputs, and include emotions, repetitions, and more.', 'GT': 0, 'Backg': 0}, {'Duration': 9, 'Sent ID': '', 'Spoken words': 'analysis saw example earlier real example discussed actually morning', 'Sent i': 90, 'Sent Text': 'we used the following customer analysis in our model.', 'GT': 0, 'Backg': 0}, {'Duration': 36, 'Sent ID': '', 'Spoken words': 'emotion really important seems one causes lead lead egregious conversation looking different behavior emotion looking big online emotions example max negative emotions also looking variation conversation ever going emotions conversation compared pick specific utterance done looking', 'Sent i': 99, 'Sent Text': 'we focused on negative emotions (denoted as neg emo) to identify turns with a negative emotional peak (i.e., single utterances that carried high negative emotional state), as well as to estimate the aggregated negative emotion throughout the conversation (i.e., the averaged negative emotion intensity).', 'GT': 0, 'Backg': 0}, {'Duration': 19, 'Sent ID': '', 'Spoken words': 'rephrasing analysis equivalent say trying capture many times efforts customer trying rephrase agents well hopefully understand also another feature', 'Sent i': 102, 'Sent Text': 'note that we used the positive emotions as a filter for other customer features, such as the rephrasing analysis.', 'GT': 0, 'Backg': 0}, {'Duration': 11, 'Sent ID': '', 'Spoken words': "asking human agents want make clear 's perfectly okay ask agent", 'Sent i': 104, 'Sent Text': 'in examining the conversation logs, we noticed that it is not unusual to find a customer asking to be transferred to a human agent.', 'GT': 0, 'Backg': 0}, {'Duration': 15, 'Sent ID': '', 'Spoken words': "however cases 's one cases example customizable human also carreon negative emotions taken care okay", 'Sent i': 108, 'Sent Text': 'the assumption is that single word (unigram) sentences are probably short customer responses (e.g., no, yes, thanks, okay), which in most cases do not contribute to the egregiousness of the conversation.', 'GT': 0, 'Backg': 0}, {'Duration': 10, 'Sent ID': '', 'Spoken words': 'finally looking interaction agent customer agent first group feature looking', 'Sent i': 110, 'Sent Text': 'we also looked at features across conversation utterance-response pairs in order to capture a more complete picture of the interac- tion between the customer and the virtual agent.', 'GT': 0, 'Backg': 0}, {'Duration': 31, 'Sent ID': '', 'Spoken words': "behavior inputs customer phones something like 'm trained give example civil third one call long sentences maybe imagine starting write long sentence explaining question something need enough use spend quite lot", 'Sent i': 108, 'Sent Text': 'the assumption is that single word (unigram) sentences are probably short customer responses (e.g., no, yes, thanks, okay), which in most cases do not contribute to the egregiousness of the conversation.', 'GT': 0, 'Backg': 0}, {'Duration': 3, 'Sent ID': '', 'Spoken words': 'time fourth efforts', 'Sent i': 116, 'Sent Text': 'these features are summarized in the last part of table 1.', 'GT': 0, 'Backg': 0}, {'Duration': 20, 'Sent ID': '', 'Spoken words': "press enter immediately got 'm turn could closely high frustration customer later group cause section looking also customer aside freezing", 'Sent i': 117, 'Sent Text': 'we also calculated the similarity between the customer’s turn and the virtual agent’s response in cases of customer rephrasing.', 'GT': 0, 'Backg': 0}, {'Duration': 4, 'Sent ID': '', 'Spoken words': 'analysis example getting results', 'Sent i': 118, 'Sent Text': 'this analysis aims to capture the reason for the customer rephrasing.', 'GT': 0, 'Backg': 0}, {'Duration': 5, 'Sent ID': '', 'Spoken words': 'similar results agents basically means', 'Sent i': 127, 'Sent Text': 'both agents are using similar underlying conversation engines, each embedded in a larger system with its own unique business logic.', 'GT': 0, 'Backg': 0}, {'Duration': 16, 'Sent ID': '', 'Spoken words': 'customer trying phrase room input agent keep getting wrong thing keep turn wrong customer expected conversation', 'Sent i': 129, 'Sent Text': 'each system logs conversations, and each conversation is a sequence of tuples, where each tuple consists of {conversation id, turn id, customer input, agent response}.', 'GT': 0, 'Backg': 0}, {'Duration': 15, 'Sent ID': '', 'Spoken words': "lens feature okay setting sample full eleven hundred conversation company another two hundred company 's", 'Sent i': 136, 'Sent Text': 'this sample included 1100 and 200 conversations for company a and company b respectively.', 'GT': 0, 'Backg': 0}, {'Duration': 27, 'Sent ID': '', 'Spoken words': 'conversation give give hci experts judge using guideline conversation exploded mute extra ordinarily bad ways conversations like see human jump save conversation okay like superman something like', 'Sent i': 139, 'Sent Text': 'given the full conversation, each judge tagged whether the conversation was egregious or not following this guideline: “conversations which are extraordinarily bad in some way, those conversations where you’d like to see a human jump in and save the conversation”.', 'GT': 0, 'Backg': 0}, {'Duration': 8, 'Sent ID': '', 'Spoken words': 'delay delay delay ability judges high around point', 'Sent i': 141, 'Sent Text': 'the interrater reliability between all judges, measured by cohen’s kappa, was 0.72 which indicates high level agreement.', 'GT': 0, 'Backg': 0}, {'Duration': 13, 'Sent ID': '', 'Spoken words': "two okay run actually non companies around eight percent conversation doug egregious 'm", 'Sent i': 140, 'Sent Text': 'we generated true binary labels by considering a conversation to be egregious if at least three of the four judges agreed.', 'GT': 0, 'Backg': 0}, {'Duration': 10, 'Sent ID': '', 'Spoken words': 'tools looking also implemented focus based whether compel due first', 'Sent i': 144, 'Sent Text': 'we also implemented two baseline models, rule-based and text-based, as follows: rule-based.', 'GT': 0, 'Backg': 0}, {'Duration': 2, 'Sent ID': '', 'Spoken words': 'model text', 'Sent i': 147, 'Sent Text': 'a model that was trained to predict egregiousness given the conversation’s text (all customer and agent’s text dur- 8judges that are hci experts and have experience in designing conversational agents systems.', 'GT': 0, 'Backg': 0}, {'Duration': 15, 'Sent ID': '', 'Spoken words': 'based model looked unique grimes feature lexicon coming emotion emotional features door based looking simple', 'Sent i': 148, 'Sent Text': 'this model was implemented using state-of-the-art textual features as in (herzig et al., 2017).', 'GT': 0, 'Backg': 0}, {'Duration': 8, 'Sent ID': '', 'Spoken words': "agent response 'm trained customer asking agent finally", 'Sent i': 147, 'Sent Text': 'a model that was trained to predict egregiousness given the conversation’s text (all customer and agent’s text dur- 8judges that are hci experts and have experience in designing conversational agents systems.', 'GT': 0, 'Backg': 0}, {'Duration': 1, 'Sent ID': '', 'Spoken words': 'implemented', 'Sent i': 148, 'Sent Text': 'this model was implemented using state-of-the-art textual features as in (herzig et al., 2017).', 'GT': 0, 'Backg': 0}, {'Duration': 3, 'Sent ID': '', 'Spoken words': 'class using v', 'Sent i': 151, 'Sent Text': 'since class distribution is unbalanced, we evaluated classification performance by using precision (p), recall (r) and f1-score (f) for each class.', 'GT': 0, 'Backg': 0}, {'Duration': 1, 'Sent ID': '', 'Spoken words': 'svm', 'Sent i': 152, 'Sent Text': 'the egr classifier was implemented using an svm with a linear kernel9.', 'GT': 0, 'Backg': 0}, {'Duration': 7, 'Sent ID': '', 'Spoken words': 'okay results okay look f one school', 'Sent i': 153, 'Sent Text': 'table 2 depicts the classification results for both classes and the three models we explored.', 'GT': 0, 'Backg': 0}, {'Duration': 12, 'Sent ID': '', 'Spoken words': 'see egregious classifiers outperforming bass baseline approach around forty percent eighty percent', 'Sent i': 154, 'Sent Text': 'the egr model significantly outperformed both baselines10.', 'GT': 0, 'Backg': 0}, {'Duration': 9, 'Sent ID': '', 'Spoken words': 'text based think also interesting look precision seems least', 'Sent i': 155, 'Sent Text': 'specifically, for the egregious class, the precision obtained by the text-based and egr models were similar.', 'GT': 0, 'Backg': 0}, {'Duration': 8, 'Sent ID': '', 'Spoken words': 'text based approaches capture send egregious using text', 'Sent i': 156, 'Sent Text': 'this indicates that the text analyzed by both models encodes some information about egregiousness.', 'GT': 0, 'Backg': 0}, {'Duration': 14, 'Sent ID': '', 'Spoken words': 'features interesting continue feature sets contribution analyses basically heading incremental time one different sets', 'Sent i': 159, 'Sent Text': 'to better understand the contributions of different sets of features to our egr model, we examined various features in an incremental fashion.', 'GT': 0, 'Backg': 0}, {'Duration': 7, 'Sent ID': '', 'Spoken words': 'feature starting agents features adding customer finally', 'Sent i': 160, 'Sent Text': 'based on the groups of feature sets that we defined in section 3, we tested the performance of different group combinations, added in the following order: agent, customer and customer-agent interactions.', 'GT': 0, 'Backg': 0}, {'Duration': 23, 'Sent ID': '', 'Spoken words': 'also get see gray column adding also goodwill gave us highest quality also interesting features coming customer along informative respect detecting egregious okay', 'Sent i': 164, 'Sent Text': 'the figure also suggests that the most informative group in terms of prediction ability is the customer group.', 'GT': 0, 'Backg': 0}, {'Duration': 21, 'Sent ID': '', 'Spoken words': "look main remember company conversations trying data using company data n't musician note tuning destroyed simple simply company data look score", 'Sent i': 167, 'Sent Text': 'for this task, we utilized the 200 annotated conversations of company b as test data, and experimented with the different models, trained on company a’s data.', 'GT': 0, 'Backg': 0}, {'Duration': 3, 'Sent ID': '', 'Spoken words': 'also somehow expected', 'Sent i': 168, 'Sent Text': 'the rule-based baseline does not require training, of course, and could be applied directly.', 'GT': 0, 'Backg': 0}, {'Duration': 19, 'Sent ID': '', 'Spoken words': "degradation nine percent still seems able detect 'd also nice seize annoyance nice look performance text based much lower", 'Sent i': 169, 'Sent Text': 'table 3 summarizes the results showing that the performance of the egr model is relatively stable (w.r.t the model’s performance when it was trained and tested on the same domain), with a degradation of only 9% in f1-score11.', 'GT': 0, 'Backg': 0}, {'Duration': 10, 'Sent ID': '', 'Spoken words': 'used fact text feature allows tied main trained okay finally', 'Sent i': 171, 'Sent Text': 'this may occur since textual features are closely tied to the training domain.', 'GT': 0, 'Backg': 0}, {'Duration': 37, 'Sent ID': '', 'Spoken words': 'mom customer phrasing analysis inspired works saikai un sunal wanted idea understand difference reasons customer phrasing setting use heard systems little bit differently stuff problems problems related setting idea turn analyze whole distribution different egregious angry class', 'Sent i': 172, 'Sent Text': 'inspired by (sarikaya, 2017; sano et al., 2017) we analyzed the customer rephrasing motivations for both the egregious and the non-egregious classes.', 'GT': 0, 'Backg': 0}, {'Duration': 6, 'Sent ID': '', 'Spoken words': 'first time always l coming called', 'Sent i': 173, 'Sent Text': 'first, we detected customer rephrasing as described in section 3.2.1, and then assigned to each its motivation.', 'GT': 0, 'Backg': 0}, {'Duration': 70, 'Sent ID': '', 'Spoken words': "basically intent detected correctly means agents response semantically file customer expected able coming limitation language generation limitation 's item intent section score customer satisfied two got agents example could agents going speak specific thing got us may broad use 's needs last elway 's 'll come dunn support intent basically 'm trained data supported agent look distribution good gorgeous see dumb much unsupported intent previous one error also lg reduction", 'Sent i': 174, 'Sent Text': 'specifically, in our setting, the relevant motivations are12: (1) natural language understanding (nlu) error - the agent’s intent detection is wrong, and thus the agent’s response is semantically far from the customer’s turn; (2) language generation (lg) limitation - the intent is detected correctly, but the customer is not satisfied by the response (for example, the response was too generic); (3) unsupported intent error - the customer’s intent is not supported by the agent.', 'GT': 0, 'Backg': 0}, {'Duration': 15, 'Sent ID': '', 'Spoken words': 'heiau non gregis one think get indicates customer tolerance blow blames get feedback agent time', 'Sent i': 175, 'Sent Text': 'in order to detect nlu errors, we measured the similarity between the first customer turn (before the rephrasing) and the agent response.', 'GT': 0, 'Backg': 0}, {'Duration': 4, 'Sent ID': '', 'Spoken words': 'actually understand case system', 'Sent i': 181, 'Sent Text': 'this indicates that customers are more tolerant of cases where the system understood their intent, but the response is not exactly what they expected, rather than cases where the system’s response was “not trained”.', 'GT': 0, 'Backg': 0}, {'Duration': 13, 'Sent ID': '', 'Spoken words': 'things ask thus conversation getting egregious fast also look arm also percentage course', 'Sent i': 183, 'Sent Text': 'we further investigated why the egr model was better at identifying egregious conversations (i.e., its recall was higher compared to the baseline models).', 'GT': 0, 'Backg': 0}, {'Duration': 1, 'Sent ID': '', 'Spoken words': 'due', 'Sent i': 185, 'Sent Text': 'those conversations were particularly prevalent with the agent’s difficulty to identify correctly the user’s intent due to nlu errors or lg limitation.', 'GT': 0, 'Backg': 0}, {'Duration': 7, 'Sent ID': '', 'Spoken words': "weight 's line 's annual company okay", 'Sent i': 187, 'Sent Text': 'in addition, the customer intents that appeared in those conversations were very diverse.', 'GT': 0, 'Backg': 0}, {'Duration': 14, 'Sent ID': '', 'Spoken words': 'conclude walker show detect egregious conversation using feature coming agent customer direction also feature', 'Sent i': 189, 'Sent Text': 'in this paper, we have shown how it is possible to detect egregious conversations using a combination of customer utterances, agent responses, and customer-agent interactional features.', 'GT': 0, 'Backg': 0}, {'Duration': 9, 'Sent ID': '', 'Spoken words': 'whole bust first main future work consul first want', 'Sent i': 191, 'Sent Text': 'in this context, future work includes collecting more data and using neural approaches (e.g., rnn, cnn) for analysis, validating our models on a range of domains beyond the two explored here.', 'GT': 0, 'Backg': 0}, {'Duration': 11, 'Sent ID': '', 'Spoken words': "every time n't want waiting end call conversation plan real time", 'Sent i': 192, 'Sent Text': 'we also plan to extend the work to detect egregious conversations in real time (e.g., for escalating to a human operators), and create log analysis tools to analyze the root causes of egregious conversations and suggest possible remedies.', 'GT': 0, 'Backg': 0}, {'Duration': 5, 'Sent ID': '', 'Spoken words': 'want collect data look approaches', 'Sent i': 191, 'Sent Text': 'in this context, future work includes collecting more data and using neural approaches (e.g., rnn, cnn) for analysis, validating our models on a range of domains beyond the two explored here.', 'GT': 0, 'Backg': 0}, {'Duration': 26, 'Sent ID': '', 'Spoken words': "order useful also integrates real alice 's tools explained root cause egregious conversations high thanks great holiday foundation lose track many feature dollar contacts 'm wondering", 'Sent i': 192, 'Sent Text': 'we also plan to extend the work to detect egregious conversations in real time (e.g., for escalating to a human operators), and create log analysis tools to analyze the root causes of egregious conversations and suggest possible remedies.', 'GT': 0, 'Backg': 0}, {'Duration': 24, 'Sent ID': '', 'Spoken words': "type feature important lie compositional lands big data tenet repeating repented state repeating imports may help complete task 'm wondering tapley feature important expected", 'Sent i': 191, 'Sent Text': 'in this context, future work includes collecting more data and using neural approaches (e.g., rnn, cnn) for analysis, validating our models on a range of domains beyond the two explored here.', 'GT': 0, 'Backg': 0}, {'Duration': 11, 'Sent ID': '', 'Spoken words': "'d last could n't hear last part repeat last also recall", 'Sent i': 192, 'Sent Text': 'we also plan to extend the work to detect egregious conversations in real time (e.g., for escalating to a human operators), and create log analysis tools to analyze the root causes of egregious conversations and suggest possible remedies.', 'GT': 0, 'Backg': 0}, {'Duration': 3, 'Sent ID': '', 'Spoken words': 'used three three', 'Sent i': 191, 'Sent Text': 'in this context, future work includes collecting more data and using neural approaches (e.g., rnn, cnn) for analysis, validating our models on a range of domains beyond the two explored here.', 'GT': 0, 'Backg': 0}, {'Duration': 15, 'Sent ID': '', 'Spoken words': 'feature sets right first ones extracted agent put segments customer decline action features many features', 'Sent i': 189, 'Sent Text': 'in this paper, we have shown how it is possible to detect egregious conversations using a combination of customer utterances, agent responses, and customer-agent interactional features.', 'GT': 0, 'Backg': 0}, {'Duration': 3, 'Sent ID': '', 'Spoken words': "right 'm wondering", 'Sent i': 190, 'Sent Text': 'as explained, the goal of this work is to give developers of automated agents tools to detect and then solve problems cre- ated by exceptionally bad conversations.', 'GT': 0, 'Backg': 0}, {'Duration': 19, 'Sent ID': '', 'Spoken words': "type features important one okay actually 's appear system analysis get featuring within group 's part work discuss line", 'Sent i': 191, 'Sent Text': 'in this context, future work includes collecting more data and using neural approaches (e.g., rnn, cnn) for analysis, validating our models on a range of domains beyond the two explored here.', 'GT': 0, 'Backg': 0}]
log_prob = -8499.340488427173
predicted sequence info:

Sent i | Sent Text                      | Duration | Spoken words                  
-------+--------------------------------+----------+-------------------------------
0      | test automated conversational  | 21       | okay high 'm name much show   
       | agents (chatbots) are becoming |          | death present work detecting  
       | widely used for various tasks  |          | conversations customers       
       | such as personal assistants or |          | virtual agents joint work ibm 
       | as customer service agents.    |          | loving high fi yorktown       
3      | still, chatbots may behave     | 7        | okay one second okay sorry    
       | extremely badly, leading to    |          | okay think                    
       | conversations so off-the-mark  |          |                               
       | that only a human agent could  |          |                               
       | step in and salvage them.      |          |                               
6      | in this paper we study         | 9        | stuff phoenician egregious    
       | detecting these egregious      |          | egregious definition          
       | conversations that can arise   |          | outstandingly bad shocking    
       | in numerous ways.              |          | heard                         
0      | test automated conversational  | 8        | known interest using virtual  
       | agents (chatbots) are becoming |          | agent increasing specifically 
       | widely used for various tasks  |          | prediction                    
       | such as personal assistants or |          |                               
       | as customer service agents.    |          |                               
1      | recent studies project that    | 5        | twenty twenty eighty percent  
       | 80% of businesses plan to use  |          | businesses                    
       | chatbots by 20201, and that    |          |                               
       | chatbots will power 85% of     |          |                               
       | customer service interactions  |          |                               
       | by the year 20202.             |          |                               
0      | test automated conversational  | 8        | virtual agents even           
       | agents (chatbots) are becoming |          | specifically look customer    
       | widely used for various tasks  |          | care main                     
       | such as personal assistants or |          |                               
       | as customer service agents.    |          |                               
1      | recent studies project that    | 5        | eighty five percent           
       | 80% of businesses plan to use  |          | interactions provide          
       | chatbots by 20201, and that    |          |                               
       | chatbots will power 85% of     |          |                               
       | customer service interactions  |          |                               
       | by the year 20202.             |          |                               
2      | this increasing usage is       | 2        | powered virtual               
       | mainly due to advances in      |          |                               
       | artificial intelligence and    |          |                               
       | natural language processing    |          |                               
       | (hirschberg and manning, 2015) |          |                               
       | along with increasingly        |          |                               
       | capable chat development       |          |                               
       | environments, leading to       |          |                               
       | improvements in conversational |          |                               
       | richness and robustness.       |          |                               
3      | still, chatbots may behave     | 15       | agents course good us however 
       | extremely badly, leading to    |          | either experience know virtual
       | conversations so off-the-mark  |          | agents might behave really bad
       | that only a human agent could  |          | lead                          
       | step in and salvage them.      |          |                               
4      | consequences of these failures | 4        | loss customer loyalty even    
       | may include loss of customer   |          |                               
       | goodwill and associated        |          |                               
       | revenue, and even exposure to  |          |                               
       | litigation if the failures can |          |                               
       | be shown to include fraudulent |          |                               
       | claims.                        |          |                               
13     | the resulting customer         | 4        | ways use okay sir             
       | frustration may not surface in |          |                               
       | easily detectable ways such as |          |                               
       | the appearance of all caps,    |          |                               
       | shouting to a speech           |          |                               
       | recognizer, or the use of      |          |                               
       | profanity or extreme           |          |                               
       | punctuation.                   |          |                               
15     | consider, for example, the     | 3        | real example conversation     
       | anonymized but representative  |          |                               
       | conversation depicted in       |          |                               
       | figure 1.                      |          |                               
16     | here the customer aims to      | 36       | n't deal let take okay        
       | understand the details of a    |          | customer left agents right    
       | flight ticket.                 |          | customer asking quotes travel 
       |                                |          | wants know details agent kind 
       |                                |          | understand telling consider   
       |                                |          | purchased ticket customer     
       |                                |          | interested n't want buy want  
       |                                |          | know details agents actually  
       |                                |          | missing gifts think           
17     | in the first two turns, the    | 13       | already wants go next online  
       | chatbot misses the customer’s  |          | lyor process rent cop customer
       | intentions, which leads to the |          | asking rule person            
       | customer asking “are you a     |          |                               
       | real person?”.                 |          |                               
18     | the customer then tries to     | 40       | response develop since        
       | explain what went wrong, but   |          | assistant trained answer      
       | the chatbot has insufficient   |          | questions drivers get ask     
       | exposure to this sort of       |          | question customer trying start
       | utterance to provide anything  |          | getting little bit annoyed ask
       | but the default response (“i’m |          | specific question got sell    
       | not trained on that”).         |          | agent picking answering 'm    
       |                                |          | trained yet 'm still learning 
       |                                |          | may want forget phase question
       |                                |          | time customer thing           
19     | the response seems to upset    | 16       | frustrated anger well         
       | the customer and leads to a    |          | pointless talk real life      
       | request for a human agent,     |          | person answer n't currently   
       | which is rejected by the       |          | live agents checked online    
       | system (“we don’t currently    |          | okay                          
       | have live agents”).            |          |                               
32     | we review related work, then   | 9        | define egregious conversations
       | we formally define the         |          | okay course bunch well top    
       | methodology for detecting      |          | elected                       
       | egregious conversations.       |          |                               
36     | these works studied the        | 9        | book festal works todd looking
       | complementary problem of       |          | computer complementary        
       | detecting and measuring user   |          | problems try                  
       | satisfaction and engagement.   |          |                               
37     | early work by (walker et al.,  | 5        | maximize data previous work   
       | 1997, 2001) discussed a        |          | coming                        
       | framework that maximizes the   |          |                               
       | user satisfaction by           |          |                               
       | considering measures such as   |          |                               
       | number of inappropriate        |          |                               
       | utterances, recognition rates, |          |                               
       | number of times user requests  |          |                               
       | repetitions, number of turns   |          |                               
       | per interaction, etc.          |          |                               
39     | other works focus on           | 2        | mine systems                  
       | predicting the user engagement |          |                               
       | in such systems.               |          |                               
43     | in our work, we likewise use   | 4        | data use dialogue logo        
       | emotion analysis as predictive |          |                               
       | features for egregious         |          |                               
       | conversation.                  |          |                               
45     | specifically, in (sarikaya,    | 19       | specific setting late late    
       | 2017) they reported on how the |          | stood two thousand seventeen  
       | different reasons affect the   |          | somewhat thought trying study 
       | users’ satisfaction.           |          | reason customers rephrasing   
       |                                |          | different reasons affect      
       |                                |          | satisfaction                  
46     | in (sano et al., 2017) they    | 2        | dissatisfaction finally       
       | focused on how to              |          |                               
       | automatically predict the      |          |                               
       | reason for user’s              |          |                               
       | dissatisfaction using          |          |                               
       | different features.            |          |                               
49     | in (walker et al., 2000;       | 7        | also looking dialog break     
       | hastie et al., 2002) the       |          | break downs walker            
       | authors also looked for        |          |                               
       | problems in a specific setting |          |                               
       | of spoken conversations.       |          |                               
53     | in (steidl et al., 2004) they  | 3        | trying torrents level         
       | measured dialogue success at   |          |                               
       | the turn level as a way of     |          |                               
       | predicting the success of a    |          |                               
       | conversation as a whole.       |          |                               
57     | all these measures may serve   | 11       | try understand utterance break
       | as reasons for a conversation  |          | data japanese chat okay       
       | turning egregious, but none    |          | dealing would like            
       | try to capture or predict it   |          |                               
       | directly.                      |          |                               
60     | they found that a combination  | 26       | sit extracted lead companies  
       | of exaggerated customer        |          | provide customer support using
       | expectations along with a      |          | virtual agents company using  
       | reduction in agent performance |          | similar line totally different
       | (e.g., failure to listen to    |          | domains one company business  
       | the consumer, being too        |          | logic course arm system       
       | intrusive) caused customers to |          | extract thousand              
       | stop using such systems.       |          |                               
64     | the objective of this work is  | 21       | conversations randomly see    
       | to reliably detect egregious   |          | local distribution            
       | conversations between a human  |          | conversation never see        
       | and a virtual agent.           |          | conversation company much     
       |                                |          | twice longer company okay     
       |                                |          | recall thought try detect     
       |                                |          | group conversation            
65     | we treat this as a binary      | 12       | treat problem binary          
       | classification task, where the |          | classification problem target 
       | target classes are “egregious” |          | classes egregious awning      
       | and “non-egregious”.           |          | gregis input classifieds      
66     | while we are currently         | 6        | basically complete            
       | applying this to complete      |          | conversation classification   
       | conversations (i.e., the       |          | done end                      
       | classification is done on the  |          |                               
       | whole conversation), some of   |          |                               
       | the features examined here     |          |                               
       | could likely be used to detect |          |                               
       | egregious conversations as     |          |                               
       | they were unfolding in real    |          |                               
       | time.                          |          |                               
67     | to perform egregious           | 22       | conversation struck dot three 
       | conversation detection,        |          | different feature sets        
       | features from both customer    |          | conversation feature coming   
       | inputs and agent responses are |          | agent response customer input 
       | extracted, together with       |          | interaction feature customer  
       | features related to the        |          | agents also low feature       
       | combination of specific inputs |          | context                       
       | and responses.                 |          |                               
66     | while we are currently         | 14       | basically whether count appeal
       | applying this to complete      |          | conversation okay point       
       | conversations (i.e., the       |          | features complete check paper 
       | classification is done on the  |          | 'll 'll 'll                   
       | whole conversation), some of   |          |                               
       | the features examined here     |          |                               
       | could likely be used to detect |          |                               
       | egregious conversations as     |          |                               
       | they were unfolding in real    |          |                               
       | time.                          |          |                               
72     | when the agent starts losing   | 8        | begin agents response first   
       | the context of a conversation, |          | week ease called repeating    
       | fails in understanding the     |          |                               
       | customer intention, or keeps   |          |                               
       | repeating the same responses,  |          |                               
       | the illusion of conversing     |          |                               
       | with a human is lost and the   |          |                               
       | conversation may become        |          |                               
       | extremely annoying.            |          |                               
75     | accurate intent detection is   | 8        | sponson analysis basically    
       | thus a fundamental             |          | aims find many time agents    
       | characteristic of well-trained |          |                               
       | virtual agents, and incorrect  |          |                               
       | intent analysis is reported as |          |                               
       | the leading cause of user      |          |                               
       | dissatisfaction (sarikaya,     |          |                               
       | 2017).                         |          |                               
77     | is often used to detect        | 6        | keep rephrasing saying 're    
       | intents, its probabilistic     |          | response similarly            
       | behavior can cause the agent   |          |                               
       | to repeat the same (or         |          |                               
       | semantically similar) response |          |                               
       | over and over again, despite   |          |                               
       | the user’s attempt to rephrase |          |                               
       | the same intent.               |          |                               
80     | we represented each sentence   | 17       | spahn 's order calculate sauna
       | by averaging the pre-trained   |          | representing sentence         
       | embeddings5 of each word in    |          | leveraging buildings sentence 
       | the sentence, calculating the  |          | using cause similarity find   
       | cosine similarity between the  |          | similar similar sentences     
       | representations.               |          |                               
86     | we extracted the possible      | 17       | set feature second feature    
       | variants of the unsupported    |          | call unsupported intent       
       | intent messages directly from  |          | analysis basically means ball 
       | the system, and later matched  |          | n't use supporting intent     
       | them with the agent responses  |          | usually answer                
       | from the logs.                 |          |                               
87     | from the customer’s point of   | 15       | something like like 'm trained
       | view, an ineffective           |          | something similar okay next   
       | interaction with a virtual     |          | feature coming customers site 
       | agent is clearly undesirable.  |          | point done                    
89     | these efforts can appear as    | 10       | customer may want could       
       | behavioral cues in the         |          | behavioral cues first family  
       | customer’s inputs, and include |          | 's emotion                    
       | emotions, repetitions, and     |          |                               
       | more.                          |          |                               
90     | we used the following customer | 9        | analysis saw example earlier  
       | analysis in our model.         |          | real example discussed        
       |                                |          | actually morning              
99     | we focused on negative         | 36       | emotion really important seems
       | emotions (denoted as neg emo)  |          | one causes lead lead egregious
       | to identify turns with a       |          | conversation looking different
       | negative emotional peak (i.e., |          | behavior emotion looking big  
       | single utterances that carried |          | online emotions example max   
       | high negative emotional        |          | negative emotions also looking
       | state), as well as to estimate |          | variation conversation ever   
       | the aggregated negative        |          | going emotions conversation   
       | emotion throughout the         |          | compared pick specific        
       | conversation (i.e., the        |          | utterance done looking        
       | averaged negative emotion      |          |                               
       | intensity).                    |          |                               
102    | note that we used the positive | 19       | rephrasing analysis equivalent
       | emotions as a filter for other |          | say trying capture many times 
       | customer features, such as the |          | efforts customer trying       
       | rephrasing analysis.           |          | rephrase agents well hopefully
       |                                |          | understand also another       
       |                                |          | feature                       
104    | in examining the conversation  | 11       | asking human agents want make 
       | logs, we noticed that it is    |          | clear 's perfectly okay ask   
       | not unusual to find a customer |          | agent                         
       | asking to be transferred to a  |          |                               
       | human agent.                   |          |                               
108    | the assumption is that single  | 15       | however cases 's one cases    
       | word (unigram) sentences are   |          | example customizable human    
       | probably short customer        |          | also carreon negative emotions
       | responses (e.g., no, yes,      |          | taken care okay               
       | thanks, okay), which in most   |          |                               
       | cases do not contribute to the |          |                               
       | egregiousness of the           |          |                               
       | conversation.                  |          |                               
110    | we also looked at features     | 10       | finally looking interaction   
       | across conversation utterance- |          | agent customer agent first    
       | response pairs in order to     |          | group feature looking         
       | capture a more complete        |          |                               
       | picture of the interac- tion   |          |                               
       | between the customer and the   |          |                               
       | virtual agent.                 |          |                               
108    | the assumption is that single  | 31       | behavior inputs customer      
       | word (unigram) sentences are   |          | phones something like 'm      
       | probably short customer        |          | trained give example civil    
       | responses (e.g., no, yes,      |          | third one call long sentences 
       | thanks, okay), which in most   |          | maybe imagine starting write  
       | cases do not contribute to the |          | long sentence explaining      
       | egregiousness of the           |          | question something need enough
       | conversation.                  |          | use spend quite lot           
116    | these features are summarized  | 3        | time fourth efforts           
       | in the last part of table 1.   |          |                               
117    | we also calculated the         | 20       | press enter immediately got 'm
       | similarity between the         |          | turn could closely high       
       | customer’s turn and the        |          | frustration customer later    
       | virtual agent’s response in    |          | group cause section looking   
       | cases of customer rephrasing.  |          | also customer aside freezing  
118    | this analysis aims to capture  | 4        | analysis example getting      
       | the reason for the customer    |          | results                       
       | rephrasing.                    |          |                               
127    | both agents are using similar  | 5        | similar results agents        
       | underlying conversation        |          | basically means               
       | engines, each embedded in a    |          |                               
       | larger system with its own     |          |                               
       | unique business logic.         |          |                               
129    | each system logs               | 16       | customer trying phrase room   
       | conversations, and each        |          | input agent keep getting wrong
       | conversation is a sequence of  |          | thing keep turn wrong customer
       | tuples, where each tuple       |          | expected conversation         
       | consists of {conversation id,  |          |                               
       | turn id, customer input, agent |          |                               
       | response}.                     |          |                               
136    | this sample included 1100 and  | 15       | lens feature okay setting     
       | 200 conversations for company  |          | sample full eleven hundred    
       | a and company b respectively.  |          | conversation company another  
       |                                |          | two hundred company 's        
139    | given the full conversation,   | 27       | conversation give give hci    
       | each judge tagged whether the  |          | experts judge using guideline 
       | conversation was egregious or  |          | conversation exploded mute    
       | not following this guideline:  |          | extra ordinarily bad ways     
       | “conversations which are       |          | conversations like see human  
       | extraordinarily bad in some    |          | jump save conversation okay   
       | way, those conversations where |          | like superman something like  
       | you’d like to see a human jump |          |                               
       | in and save the conversation”. |          |                               
141    | the interrater reliability     | 8        | delay delay delay ability     
       | between all judges, measured   |          | judges high around point      
       | by cohen’s kappa, was 0.72     |          |                               
       | which indicates high level     |          |                               
       | agreement.                     |          |                               
140    | we generated true binary       | 13       | two okay run actually non     
       | labels by considering a        |          | companies around eight percent
       | conversation to be egregious   |          | conversation doug egregious 'm
       | if at least three of the four  |          |                               
       | judges agreed.                 |          |                               
144    | we also implemented two        | 10       | tools looking also implemented
       | baseline models, rule-based    |          | focus based whether compel due
       | and text-based, as follows:    |          | first                         
       | rule-based.                    |          |                               
147    | a model that was trained to    | 2        | model text                    
       | predict egregiousness given    |          |                               
       | the conversation’s text (all   |          |                               
       | customer and agent’s text dur- |          |                               
       | 8judges that are hci experts   |          |                               
       | and have experience in         |          |                               
       | designing conversational       |          |                               
       | agents systems.                |          |                               
148    | this model was implemented     | 15       | based model looked unique     
       | using state-of-the-art textual |          | grimes feature lexicon coming 
       | features as in (herzig et al., |          | emotion emotional features    
       | 2017).                         |          | door based looking simple     
147    | a model that was trained to    | 8        | agent response 'm trained     
       | predict egregiousness given    |          | customer asking agent finally 
       | the conversation’s text (all   |          |                               
       | customer and agent’s text dur- |          |                               
       | 8judges that are hci experts   |          |                               
       | and have experience in         |          |                               
       | designing conversational       |          |                               
       | agents systems.                |          |                               
148    | this model was implemented     | 1        | implemented                   
       | using state-of-the-art textual |          |                               
       | features as in (herzig et al., |          |                               
       | 2017).                         |          |                               
151    | since class distribution is    | 3        | class using v                 
       | unbalanced, we evaluated       |          |                               
       | classification performance by  |          |                               
       | using precision (p), recall    |          |                               
       | (r) and f1-score (f) for each  |          |                               
       | class.                         |          |                               
152    | the egr classifier was         | 1        | svm                           
       | implemented using an svm with  |          |                               
       | a linear kernel9.              |          |                               
153    | table 2 depicts the            | 7        | okay results okay look f one  
       | classification results for     |          | school                        
       | both classes and the three     |          |                               
       | models we explored.            |          |                               
154    | the egr model significantly    | 12       | see egregious classifiers     
       | outperformed both baselines10. |          | outperforming bass baseline   
       |                                |          | approach around forty percent 
       |                                |          | eighty percent                
155    | specifically, for the          | 9        | text based think also         
       | egregious class, the precision |          | interesting look precision    
       | obtained by the text-based and |          | seems least                   
       | egr models were similar.       |          |                               
156    | this indicates that the text   | 8        | text based approaches capture 
       | analyzed by both models        |          | send egregious using text     
       | encodes some information about |          |                               
       | egregiousness.                 |          |                               
159    | to better understand the       | 14       | features interesting continue 
       | contributions of different     |          | feature sets contribution     
       | sets of features to our egr    |          | analyses basically heading    
       | model, we examined various     |          | incremental time one different
       | features in an incremental     |          | sets                          
       | fashion.                       |          |                               
160    | based on the groups of feature | 7        | feature starting agents       
       | sets that we defined in        |          | features adding customer      
       | section 3, we tested the       |          | finally                       
       | performance of different group |          |                               
       | combinations, added in the     |          |                               
       | following order: agent,        |          |                               
       | customer and customer-agent    |          |                               
       | interactions.                  |          |                               
164    | the figure also suggests that  | 23       | also get see gray column      
       | the most informative group in  |          | adding also goodwill gave us  
       | terms of prediction ability is |          | highest quality also          
       | the customer group.            |          | interesting features coming   
       |                                |          | customer along informative    
       |                                |          | respect detecting egregious   
       |                                |          | okay                          
167    | for this task, we utilized the | 21       | look main remember company    
       | 200 annotated conversations of |          | conversations trying data     
       | company b as test data, and    |          | using company data n't        
       | experimented with the          |          | musician note tuning destroyed
       | different models, trained on   |          | simple simply company data    
       | company a’s data.              |          | look score                    
168    | the rule-based baseline does   | 3        | also somehow expected         
       | not require training, of       |          |                               
       | course, and could be applied   |          |                               
       | directly.                      |          |                               
169    | table 3 summarizes the results | 19       | degradation nine percent still
       | showing that the performance   |          | seems able detect 'd also nice
       | of the egr model is relatively |          | seize annoyance nice look     
       | stable (w.r.t the model’s      |          | performance text based much   
       | performance when it was        |          | lower                         
       | trained and tested on the same |          |                               
       | domain), with a degradation of |          |                               
       | only 9% in f1-score11.         |          |                               
171    | this may occur since textual   | 10       | used fact text feature allows 
       | features are closely tied to   |          | tied main trained okay finally
       | the training domain.           |          |                               
172    | inspired by (sarikaya, 2017;   | 37       | mom customer phrasing analysis
       | sano et al., 2017) we analyzed |          | inspired works saikai un sunal
       | the customer rephrasing        |          | wanted idea understand        
       | motivations for both the       |          | difference reasons customer   
       | egregious and the non-         |          | phrasing setting use heard    
       | egregious classes.             |          | systems little bit differently
       |                                |          | stuff problems problems       
       |                                |          | related setting idea turn     
       |                                |          | analyze whole distribution    
       |                                |          | different egregious angry     
       |                                |          | class                         
173    | first, we detected customer    | 6        | first time always l coming    
       | rephrasing as described in     |          | called                        
       | section 3.2.1, and then        |          |                               
       | assigned to each its           |          |                               
       | motivation.                    |          |                               
174    | specifically, in our setting,  | 70       | basically intent detected     
       | the relevant motivations       |          | correctly means agents        
       | are12: (1) natural language    |          | response semantically file    
       | understanding (nlu) error -    |          | customer expected able coming 
       | the agent’s intent detection   |          | limitation language generation
       | is wrong, and thus the agent’s |          | limitation 's item intent     
       | response is semantically far   |          | section score customer        
       | from the customer’s turn; (2)  |          | satisfied two got agents      
       | language generation (lg)       |          | example could agents going    
       | limitation - the intent is     |          | speak specific thing got us   
       | detected correctly, but the    |          | may broad use 's needs last   
       | customer is not satisfied by   |          | elway 's 'll come dunn support
       | the response (for example, the |          | intent basically 'm trained   
       | response was too generic); (3) |          | data supported agent look     
       | unsupported intent error - the |          | distribution good gorgeous see
       | customer’s intent is not       |          | dumb much unsupported intent  
       | supported by the agent.        |          | previous one error also lg    
       |                                |          | reduction                     
175    | in order to detect nlu errors, | 15       | heiau non gregis one think get
       | we measured the similarity     |          | indicates customer tolerance  
       | between the first customer     |          | blow blames get feedback agent
       | turn (before the rephrasing)   |          | time                          
       | and the agent response.        |          |                               
181    | this indicates that customers  | 4        | actually understand case      
       | are more tolerant of cases     |          | system                        
       | where the system understood    |          |                               
       | their intent, but the response |          |                               
       | is not exactly what they       |          |                               
       | expected, rather than cases    |          |                               
       | where the system’s response    |          |                               
       | was “not trained”.             |          |                               
183    | we further investigated why    | 13       | things ask thus conversation  
       | the egr model was better at    |          | getting egregious fast also   
       | identifying egregious          |          | look arm also percentage      
       | conversations (i.e., its       |          | course                        
       | recall was higher compared to  |          |                               
       | the baseline models).          |          |                               
185    | those conversations were       | 1        | due                           
       | particularly prevalent with    |          |                               
       | the agent’s difficulty to      |          |                               
       | identify correctly the user’s  |          |                               
       | intent due to nlu errors or lg |          |                               
       | limitation.                    |          |                               
187    | in addition, the customer      | 7        | weight 's line 's annual      
       | intents that appeared in those |          | company okay                  
       | conversations were very        |          |                               
       | diverse.                       |          |                               
189    | in this paper, we have shown   | 14       | conclude walker show detect   
       | how it is possible to detect   |          | egregious conversation using  
       | egregious conversations using  |          | feature coming agent customer 
       | a combination of customer      |          | direction also feature        
       | utterances, agent responses,   |          |                               
       | and customer-agent             |          |                               
       | interactional features.        |          |                               
191    | in this context, future work   | 9        | whole bust first main future  
       | includes collecting more data  |          | work consul first want        
       | and using neural approaches    |          |                               
       | (e.g., rnn, cnn) for analysis, |          |                               
       | validating our models on a     |          |                               
       | range of domains beyond the    |          |                               
       | two explored here.             |          |                               
192    | we also plan to extend the     | 11       | every time n't want waiting   
       | work to detect egregious       |          | end call conversation plan    
       | conversations in real time     |          | real time                     
       | (e.g., for escalating to a     |          |                               
       | human operators), and create   |          |                               
       | log analysis tools to analyze  |          |                               
       | the root causes of egregious   |          |                               
       | conversations and suggest      |          |                               
       | possible remedies.             |          |                               
191    | in this context, future work   | 5        | want collect data look        
       | includes collecting more data  |          | approaches                    
       | and using neural approaches    |          |                               
       | (e.g., rnn, cnn) for analysis, |          |                               
       | validating our models on a     |          |                               
       | range of domains beyond the    |          |                               
       | two explored here.             |          |                               
192    | we also plan to extend the     | 26       | order useful also integrates  
       | work to detect egregious       |          | real alice 's tools explained 
       | conversations in real time     |          | root cause egregious          
       | (e.g., for escalating to a     |          | conversations high thanks     
       | human operators), and create   |          | great holiday foundation lose 
       | log analysis tools to analyze  |          | track many feature dollar     
       | the root causes of egregious   |          | contacts 'm wondering         
       | conversations and suggest      |          |                               
       | possible remedies.             |          |                               
191    | in this context, future work   | 24       | type feature important lie    
       | includes collecting more data  |          | compositional lands big data  
       | and using neural approaches    |          | tenet repeating repented state
       | (e.g., rnn, cnn) for analysis, |          | repeating imports may help    
       | validating our models on a     |          | complete task 'm wondering    
       | range of domains beyond the    |          | tapley feature important      
       | two explored here.             |          | expected                      
192    | we also plan to extend the     | 11       | 'd last could n't hear last   
       | work to detect egregious       |          | part repeat last also recall  
       | conversations in real time     |          |                               
       | (e.g., for escalating to a     |          |                               
       | human operators), and create   |          |                               
       | log analysis tools to analyze  |          |                               
       | the root causes of egregious   |          |                               
       | conversations and suggest      |          |                               
       | possible remedies.             |          |                               
191    | in this context, future work   | 3        | used three three              
       | includes collecting more data  |          |                               
       | and using neural approaches    |          |                               
       | (e.g., rnn, cnn) for analysis, |          |                               
       | validating our models on a     |          |                               
       | range of domains beyond the    |          |                               
       | two explored here.             |          |                               
189    | in this paper, we have shown   | 15       | feature sets right first ones 
       | how it is possible to detect   |          | extracted agent put segments  
       | egregious conversations using  |          | customer decline action       
       | a combination of customer      |          | features many features        
       | utterances, agent responses,   |          |                               
       | and customer-agent             |          |                               
       | interactional features.        |          |                               
190    | as explained, the goal of this | 3        | right 'm wondering            
       | work is to give developers of  |          |                               
       | automated agents tools to      |          |                               
       | detect and then solve problems |          |                               
       | cre- ated by exceptionally bad |          |                               
       | conversations.                 |          |                               
191    | in this context, future work   | 19       | type features important one   
       | includes collecting more data  |          | okay actually 's appear system
       | and using neural approaches    |          | analysis get featuring within 
       | (e.g., rnn, cnn) for analysis, |          | group 's part work discuss    
       | validating our models on a     |          | line                          
       | range of domains beyond the    |          |                               
       | two explored here.             |          |                               


